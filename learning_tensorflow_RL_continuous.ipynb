{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import collections\n",
    "import numpy as np\n",
    "import statistics\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from typing import Any, List, Sequence, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContinuousActor(tf.keras.Model):\n",
    "    \"\"\"Actor that outputs a policy directly\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_actions: int,\n",
    "        num_hidden_units: int\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.means = layers.Dense(num_actions, \n",
    "        # activation = 'tanh'\n",
    "        )\n",
    "        # self.stds = lambda x: tf.zeros(num_actions)\n",
    "        self.stds = layers.Dense(num_actions, activation='relu')\n",
    "        # tf.ones(num_actions) * 0.25\n",
    "    def call(self, inputs: tf.Tensor):\n",
    "        means = self.means(inputs)\n",
    "        stds = self.stds(inputs)\n",
    "        stds = tf.clip_by_value(stds, 1.0e-3, 1)\n",
    "        return tfp.distributions.MultivariateNormalDiag(loc = means, scale_diag = tf.exp(stds))\n",
    "\n",
    "\n",
    "class ActorCritic(tf.keras.Model):\n",
    "    \"\"\"combined actor-critic network. \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_actions: int,\n",
    "        num_hidden_units: int\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.common = layers.Dense(num_hidden_units, activation = 'relu')\n",
    "        # outputs scale, location params for mvn\n",
    "        self.actor = ContinuousActor(num_actions, num_hidden_units) #layers.Dense(num_actions)\n",
    "        self.critic = layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs: tf.Tensor):\n",
    "        x = self.common(inputs)\n",
    "        return self.actor(x), self.critic(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        gamma: float, \n",
    "        entropy_coef: float,\n",
    "        vf_coef: float,\n",
    "        model: tf.keras.Model, \n",
    "        optimizer: tf.keras.optimizers.Optimizer,\n",
    "        summary_writer,\n",
    "        debug = False):\n",
    "\n",
    "        # discount rate\n",
    "        self.gamma = tf.constant(gamma)\n",
    "        self.entropy_coef = tf.constant(entropy_coef)\n",
    "        self.vf_coef = tf.constant(vf_coef)\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        # creates a dictionary of tensor arrays to write to\n",
    "        self.memory = self._init_memory()\n",
    "        self.loss = tf.keras.losses.Huber(reduction = tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "        self.model.compile(optimizer=self.optimizer)\n",
    "        self.summary_writer = summary_writer\n",
    "\n",
    "        # switch for analysis\n",
    "        self.DEBUG = debug\n",
    "        if self.DEBUG:\n",
    "            self.debug_val = 0\n",
    "\n",
    "    def _init_memory(self):\n",
    "        return {\n",
    "                'action' : tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True),\n",
    "                'state' : tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True),\n",
    "                'next_state' : tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True),\n",
    "                'action_probs': tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True),\n",
    "                'values' : tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True),\n",
    "                'rewards' : tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True),\n",
    "                'done' : tf.TensorArray(dtype=tf.int32, size=0, dynamic_size=True)\n",
    "        }\n",
    "\n",
    "    \n",
    "    def _get_action(self, state):\n",
    "\n",
    "        policy, value = self.model(\n",
    "                tf.expand_dims(tf.constant(state, tf.float32), 0)\n",
    "            )\n",
    "        action = policy.sample()[0]\n",
    "\n",
    "        return tf.tanh(action), policy, value\n",
    "        # return tf.clip_by_value(action, -0.99, 0.99), policy, value\n",
    "    \n",
    "    def get_action(self, state, step):\n",
    "\n",
    "        # run the model\n",
    "        action, policy, _ = self._get_action(state)\n",
    "\n",
    "        if self.DEBUG:\n",
    "            with self.summary_writer.as_default():\n",
    "                tf.summary.scalar('mean1', policy.mean()[0][0], step = self.debug_val)\n",
    "                tf.summary.scalar('mean2', policy.mean()[0][1], step = self.debug_val)\n",
    "                tf.summary.scalar('std1', policy.stddev()[0][0], step = self.debug_val)\n",
    "                tf.summary.scalar('std2', policy.stddev()[0][1], step = self.debug_val)\n",
    "\n",
    "            self.debug_val += 1\n",
    "\n",
    "        return action\n",
    "\n",
    "    def log(self, action, state, next_state, reward, done, step):\n",
    "\n",
    "        \"\"\"\n",
    "        Logs results into memory - not all used necessarily\n",
    "        \"\"\"\n",
    "\n",
    "        self.memory['action'].write(\n",
    "            step, \n",
    "            tf.constant(action, tf.float32)\n",
    "            ).mark_used()\n",
    "\n",
    "        self.memory['state'].write(\n",
    "            step, \n",
    "            tf.constant(state, tf.float32)\n",
    "            ).mark_used()\n",
    "\n",
    "        self.memory['next_state'].write(\n",
    "            step, \n",
    "            tf.constant(next_state, tf.float32)\n",
    "            ).mark_used()\n",
    "\n",
    "        self.memory['rewards'].write(\n",
    "            step, \n",
    "            tf.constant(reward, tf.float32)\n",
    "            ).mark_used()\n",
    "\n",
    "        self.memory['done'].write(\n",
    "            step, \n",
    "            tf.constant(done, tf.int32)\n",
    "            ).mark_used()\n",
    "\n",
    "    def get_expected_return(\n",
    "        self,\n",
    "        rewards: tf.Tensor,\n",
    "        standardize: bool = True):\n",
    "        \"\"\"Compute expected returns\"\"\"\n",
    "\n",
    "        n = tf.shape(rewards)[0] \n",
    "        returns = tf.TensorArray(dtype=tf.float32, size=n)\n",
    "\n",
    "        # start at last reward and then accumulate reward sums into returns array\n",
    "        rewards = rewards[::-1]\n",
    "        discounted_sum = tf.constant(0.0)\n",
    "        discounted_sum_shape = discounted_sum.shape\n",
    "        for i in tf.range(n):\n",
    "            reward = rewards[i]\n",
    "            discounted_sum = reward + self.gamma * discounted_sum # discounted_sum= 0 for last reward (i.e. first element in loop)\n",
    "            discounted_sum.set_shape(discounted_sum_shape)\n",
    "            returns = returns.write(i, discounted_sum)\n",
    "        returns = returns.stack()[::-1] # reverse order back to original\n",
    "\n",
    "        if standardize:\n",
    "            returns = ((returns - tf.reduce_mean(returns)) / \n",
    "                        (tf.math.reduce_std(returns) + eps))\n",
    "        \n",
    "        return returns \n",
    "\n",
    "    def update(self, episode: int):\n",
    "\n",
    "        states = self.memory['state'].gather([i for i in tf.range(self.memory['state'].size())])\n",
    "        # tf.expand_dims(self.memory['state'].gather([i for i in tf.range(self.memory['state'].size())]), 1)\n",
    "        rewards = self.memory['rewards'].gather([i for i in tf.range(self.memory['rewards'].size())])\n",
    "        actions = self.memory['action'].gather([i for i in tf.range(self.memory['action'].size())])\n",
    "        returns = self.get_expected_return(rewards = rewards, standardize=True)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            policy, values = self.model(states)\n",
    "\n",
    "            # calculate the loss values\n",
    "            loss = self.compute_loss(\n",
    "                actions, \n",
    "                policy, \n",
    "                values,\n",
    "                returns,\n",
    "                episode)\n",
    "\n",
    "        # compute the gradients from the loss\n",
    "        grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.model.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "\n",
    "        with self.summary_writer.as_default():\n",
    "            tf.summary.scalar('loss', loss, step = episode)\n",
    "            tf.summary.scalar('episode_reward', tf.reduce_sum(rewards), step = episode)\n",
    "\n",
    "        # wipe memory for next episode\n",
    "        self.memory = self._init_memory()\n",
    "        \n",
    "    def compute_loss(\n",
    "        self,\n",
    "        actions: tf.Tensor,\n",
    "        policy: tf.Tensor,\n",
    "        values: tf.Tensor,\n",
    "        returns: tf.Tensor,\n",
    "        episode: int\n",
    "    ) -> tf.Tensor:\n",
    "        \"\"\"Computes combined actor-critic loss\"\"\"\n",
    "        # print(f'returns: {tf.shape(returns)}; values: {tf.shape(values)}')\n",
    "        advantage = returns - tf.squeeze(values)\n",
    "\n",
    "        critic_loss = self.vf_coef*self.loss(tf.squeeze(values), returns)#tf.math.square(advantage)\n",
    "\n",
    "        entropy_loss = -self.entropy_coef * policy.entropy()\n",
    "\n",
    "        # squashing correction\n",
    "        log_probs = tf.expand_dims(policy.log_prob(actions), axis = 1)\n",
    "        # stopping gradient for advantage dramatically improves stability!\n",
    "        actor_loss = tf.reduce_sum(-log_probs - tf.squeeze(tf.math.log(1 - tf.math.pow(actions, 2) + 1.0e-10)), axis=1) * tf.stop_gradient(advantage)\n",
    "\n",
    "        with self.summary_writer.as_default():\n",
    "            tf.summary.scalar('actor_loss', tf.reduce_mean(actor_loss), step = episode)\n",
    "            tf.summary.scalar('critic_loss', tf.reduce_mean(critic_loss), step = episode)\n",
    "            tf.summary.scalar('entropy_loss', tf.reduce_mean(entropy_loss), step = episode)\n",
    "\n",
    "        return tf.reduce_mean(actor_loss + critic_loss + entropy_loss)\n",
    "\n",
    "def get_next_run(log_dir):\n",
    "    next_run = max([0]+[int(j) for j in [i.split('_')[-1] for i in os.listdir(log_dir)] if j.isdigit()]) + 1\n",
    "    return log_dir + f'/run_{next_run}'\n",
    "\n",
    "def train(agent, env, num_episodes, seed):\n",
    "    \n",
    "    for i in range(num_episodes):\n",
    "        state, _ = env.reset(seed = seed)\n",
    "        done = False\n",
    "        step = 0\n",
    "        while not done:\n",
    "            action = agent.get_action(state, step)\n",
    "            next_state, reward, terminated, truncated, info = env.step(np.array(action))\n",
    "            done = terminated or truncated\n",
    "            agent.log(action, state, next_state, reward, done, step)\n",
    "            state = next_state\n",
    "\n",
    "            step += 1\n",
    "        agent.update(i)\n",
    "\n",
    "def test(agent, env, num_episodes, seed):\n",
    "\n",
    "    for i in range(num_episodes):\n",
    "        state, _ = env.reset(seed = seed)\n",
    "        done = False\n",
    "        step = 0\n",
    "        while not done:\n",
    "            action = agent.get_action(state, step)\n",
    "            next_state, reward, terminated, truncated, info = env.step(np.array(action))\n",
    "            done = terminated or truncated\n",
    "            state = next_state\n",
    "\n",
    "            step += 1\n",
    "    env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create tensorboard logs\n",
    "LOGS = './logs'\n",
    "if not os.path.exists(LOGS):\n",
    "    os.mkdir(LOGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving logs to:  ./logs/run_143\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "env = gym.make('LunarLanderContinuous-v2')\n",
    "eps = np.finfo(np.float32).eps.item()\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0007, clipnorm=0.5)\n",
    "num_actions = env.action_space.shape[0]\n",
    "num_hidden_units = 256\n",
    "model = ActorCritic(num_actions, num_hidden_units)\n",
    "\n",
    "log_dir = get_next_run(LOGS) \n",
    "print('Saving logs to: ', log_dir)\n",
    "summary_writer = tf.summary.create_file_writer(logdir = log_dir)\n",
    "agent = Agent(0.99, 0.0, 0.4, model, optimizer, summary_writer, debug=True)\n",
    "\n",
    "NUM_EPISODES=600\n",
    "train(agent, env, NUM_EPISODES, seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.84584044e-05,  8.14826722e-03, -4.40632277e-03, -2.24742149e-03,\n",
       "        5.62189279e-05,  1.10504436e-03,  0.00000000e+00,  0.00000000e+00])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gymnasium.wrappers import NormalizeObservation\n",
    "env = NormalizeObservation(env)\n",
    "state, _ = env.reset()\n",
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPISODES=5\n",
    "env = gym.make('LunarLanderContinuous-v2', render_mode='human')\n",
    "test(agent, env, NUM_EPISODES, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN / sequence model\n",
    "Try to create an RL agent with an RNN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = tf.keras.Sequential(\n",
    "    layers.LSTM(128)\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContinuousActor(tf.keras.Model):\n",
    "    \"\"\"Actor that outputs a policy directly\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_actions: int,\n",
    "        num_hidden_units: int\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.means = layers.Dense(num_actions)\n",
    "        self.stds = lambda x: tf.zeros(num_actions)\n",
    "        # self.stds = layers.Dense(num_actions, activation='relu')\n",
    "        # tf.ones(num_actions) * 0.25\n",
    "    def call(self, inputs: tf.Tensor):\n",
    "        means = self.means(inputs)\n",
    "        stds = self.stds(inputs)\n",
    "        # stds = tf.clip_by_value(stds, 1.0e-3, 1)\n",
    "        return tfp.distributions.MultivariateNormalDiag(loc = means, scale_diag = tf.exp(stds))\n",
    "\n",
    "\n",
    "class RecurrentActorCritic(tf.keras.Model):\n",
    "    \"\"\"combined actor-critic network. \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_actions: int,\n",
    "        num_hidden_units: int\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.common = layers.LSTM(num_hidden_units)\n",
    "        # outputs scale, location params for mvn\n",
    "        self.actor = ContinuousActor(num_actions, num_hidden_units) \n",
    "        self.critic = layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs: tf.Tensor):\n",
    "        x = self.common(inputs)\n",
    "        return self.actor(x), self.critic(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecurrentAgent():\n",
    "\n",
    "    def __init__(\n",
    "        self, \n",
    "        gamma: float, \n",
    "        entropy_coef: float,\n",
    "        vf_coef: float,\n",
    "        window_size: int,\n",
    "        model: tf.keras.Model, \n",
    "        optimizer: tf.keras.optimizers.Optimizer,\n",
    "        summary_writer,\n",
    "        debug = False):\n",
    "\n",
    "        # discount rate\n",
    "        self.gamma = tf.constant(gamma)\n",
    "        self.entropy_coef = tf.constant(entropy_coef)\n",
    "        self.vf_coef = tf.constant(vf_coef)\n",
    "        self.window_size = tf.constant(window_size)\n",
    "        self.model = model\n",
    "        self.optimizer = optimizer\n",
    "\n",
    "        # creates a dictionary of tensor arrays to write to\n",
    "        self.memory = self._init_memory()\n",
    "        self.loss = tf.keras.losses.Huber(reduction = tf.keras.losses.Reduction.NONE)\n",
    "\n",
    "        self.model.compile(optimizer=self.optimizer)\n",
    "        self.summary_writer = summary_writer\n",
    "\n",
    "        # switch for analysis\n",
    "        self.DEBUG = debug\n",
    "        if self.DEBUG:\n",
    "            self.debug_val = 0\n",
    "\n",
    "    def _init_memory(self):\n",
    "        return {\n",
    "                'action' : tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True),\n",
    "                'state' : tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True),\n",
    "                'next_state' : tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True),\n",
    "                'action_probs': tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True),\n",
    "                'values' : tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True),\n",
    "                'rewards' : tf.TensorArray(dtype=tf.float32, size=0, dynamic_size=True),\n",
    "                'done' : tf.TensorArray(dtype=tf.int32, size=0, dynamic_size=True)\n",
    "        }\n",
    "\n",
    "    def _pad_input(self, new_state):\n",
    "        \n",
    "        # get previous states and combine with new_state\n",
    "        if self.memory['state'].size() > 0:\n",
    "            last_n = self.memory['state'].size()\n",
    "            first_n = np.max([0, last_n - self.window_size], 0)\n",
    "            prev_states = self.memory['state'].gather([i for i in tf.range(first_n, last_n)])\n",
    "            combined_states = tf.concat([tf.expand_dims(new_state, 0), prev_states], axis =0)\n",
    "        else:\n",
    "            combined_states = tf.expand_dims(new_state, 0)\n",
    "\n",
    "        # get size of padding - 0 if we have enough\n",
    "        pad_size = np.max([0, self.window_size-tf.shape(combined_states)[0]], axis = 0)\n",
    "        \n",
    "        # get the padded vals\n",
    "        padded = tf.pad(combined_states, [[0,pad_size],[0,0]])\n",
    "        padded = tf.expand_dims(padded, 0)\n",
    "\n",
    "        return padded\n",
    "    \n",
    "    def _get_action(self, state):\n",
    "\n",
    "        padded = self._pad_input(state)\n",
    "\n",
    "        policy, value = self.model(padded)\n",
    "        action = policy.sample()[0]\n",
    "\n",
    "        return tf.tanh(action), policy, value\n",
    "        # return tf.clip_by_value(action, -0.99, 0.99), policy, value\n",
    "    \n",
    "    def get_action(self, state, step):\n",
    "\n",
    "        # run the model\n",
    "        action, policy, _ = self._get_action(state)\n",
    "\n",
    "        if self.DEBUG:\n",
    "            with self.summary_writer.as_default():\n",
    "                tf.summary.scalar('mean1', policy.mean()[0][0], step = self.debug_val)\n",
    "                tf.summary.scalar('mean2', policy.mean()[0][1], step = self.debug_val)\n",
    "                tf.summary.scalar('std1', policy.stddev()[0][0], step = self.debug_val)\n",
    "                tf.summary.scalar('std2', policy.stddev()[0][1], step = self.debug_val)\n",
    "\n",
    "            self.debug_val += 1\n",
    "\n",
    "        return action\n",
    "\n",
    "    def log(self, action, state, next_state, reward, done, step):\n",
    "\n",
    "        \"\"\"\n",
    "        Logs results into memory - not all used necessarily\n",
    "        \"\"\"\n",
    "\n",
    "        self.memory['action'].write(\n",
    "            step, \n",
    "            tf.constant(action, tf.float32)\n",
    "            ).mark_used()\n",
    "\n",
    "        self.memory['state'].write(\n",
    "            step, \n",
    "            tf.constant(state, tf.float32)\n",
    "            ).mark_used()\n",
    "\n",
    "        self.memory['next_state'].write(\n",
    "            step, \n",
    "            tf.constant(next_state, tf.float32)\n",
    "            ).mark_used()\n",
    "\n",
    "        self.memory['rewards'].write(\n",
    "            step, \n",
    "            tf.constant(reward, tf.float32)\n",
    "            ).mark_used()\n",
    "\n",
    "        self.memory['done'].write(\n",
    "            step, \n",
    "            tf.constant(done, tf.int32)\n",
    "            ).mark_used()\n",
    "\n",
    "    def get_expected_return(\n",
    "        self,\n",
    "        rewards: tf.Tensor,\n",
    "        standardize: bool = True):\n",
    "        \"\"\"Compute expected returns\"\"\"\n",
    "\n",
    "        n = tf.shape(rewards)[0] \n",
    "        returns = tf.TensorArray(dtype=tf.float32, size=n)\n",
    "\n",
    "        # start at last reward and then accumulate reward sums into returns array\n",
    "        rewards = rewards[::-1]\n",
    "        discounted_sum = tf.constant(0.0)\n",
    "        discounted_sum_shape = discounted_sum.shape\n",
    "        for i in tf.range(n):\n",
    "            reward = rewards[i]\n",
    "            discounted_sum = reward + self.gamma * discounted_sum # discounted_sum= 0 for last reward (i.e. first element in loop)\n",
    "            discounted_sum.set_shape(discounted_sum_shape)\n",
    "            returns = returns.write(i, discounted_sum)\n",
    "        returns = returns.stack()[::-1] # reverse order back to original\n",
    "\n",
    "        if standardize:\n",
    "            returns = ((returns - tf.reduce_mean(returns)) / \n",
    "                        (tf.math.reduce_std(returns) + eps))\n",
    "        \n",
    "        return returns\n",
    "\n",
    "    def _prepare_states_for_lstm(self, states):\n",
    "        \"\"\"wraps states into lstm sequence format\"\"\"\n",
    "        ## need the initial k \n",
    "\n",
    "        initial_padded_states = tf.convert_to_tensor([tf.pad(states[:(i+1)][::-1], [[0,np.max([0, self.window_size-(i+1)], axis = 0)],[0,0]]) for i in tf.range(0, self.window_size)])\n",
    "        remaining_states = tf.convert_to_tensor([states[(i-self.window_size):i] for i in tf.range(self.window_size, tf.shape(states)[0])])\n",
    "        combined_states = tf.concat([initial_padded_states, remaining_states], axis = 0)\n",
    "\n",
    "        return combined_states\n",
    "        \n",
    "\n",
    "    def update(self, episode: int):\n",
    "\n",
    "        states = self.memory['state'].gather([i for i in tf.range(self.memory['state'].size())])\n",
    "        states = self._prepare_states_for_lstm(states)\n",
    "        rewards = self.memory['rewards'].gather([i for i in tf.range(self.memory['rewards'].size())])\n",
    "        actions = self.memory['action'].gather([i for i in tf.range(self.memory['action'].size())])\n",
    "        returns = self.get_expected_return(rewards = rewards, standardize=True)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "\n",
    "            policy, values = self.model(states)\n",
    "\n",
    "            # calculate the loss values\n",
    "            loss = self.compute_loss(\n",
    "                actions, \n",
    "                policy, \n",
    "                values,\n",
    "                returns,\n",
    "                episode)\n",
    "\n",
    "        # compute the gradients from the loss\n",
    "        grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.model.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "\n",
    "        with self.summary_writer.as_default():\n",
    "            tf.summary.scalar('loss', loss, step = episode)\n",
    "            tf.summary.scalar('episode_reward', tf.reduce_sum(rewards), step = episode)\n",
    "\n",
    "        # wipe memory for next episode\n",
    "        self.memory = self._init_memory()\n",
    "        \n",
    "    def compute_loss(\n",
    "        self,\n",
    "        actions: tf.Tensor,\n",
    "        policy: tf.Tensor,\n",
    "        values: tf.Tensor,\n",
    "        returns: tf.Tensor,\n",
    "        episode: int\n",
    "    ) -> tf.Tensor:\n",
    "        \"\"\"Computes combined actor-critic loss\"\"\"\n",
    "        # print(f'returns: {tf.shape(returns)}; values: {tf.shape(values)}')\n",
    "        advantage = returns - tf.squeeze(values)\n",
    "\n",
    "        critic_loss = self.vf_coef*self.loss(tf.squeeze(values), returns)#tf.math.square(advantage)\n",
    "\n",
    "        entropy_loss = -self.entropy_coef * policy.entropy()\n",
    "\n",
    "        # squashing correction\n",
    "        log_probs = tf.expand_dims(policy.log_prob(actions), axis = 1)\n",
    "        # stopping gradient for advantage dramatically improves stability!\n",
    "        actor_loss = tf.reduce_sum(-log_probs - tf.squeeze(tf.math.log(1 - tf.math.pow(actions, 2) + 1.0e-10)), axis=1) * tf.stop_gradient(advantage)\n",
    "\n",
    "        with self.summary_writer.as_default():\n",
    "            tf.summary.scalar('actor_loss', tf.reduce_mean(actor_loss), step = episode)\n",
    "            tf.summary.scalar('critic_loss', tf.reduce_mean(critic_loss), step = episode)\n",
    "            tf.summary.scalar('entropy_loss', tf.reduce_mean(entropy_loss), step = episode)\n",
    "\n",
    "        return tf.reduce_mean(actor_loss + critic_loss + entropy_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving logs to:  ./logs/run_153\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "env = gym.make('LunarLanderContinuous-v2')\n",
    "eps = np.finfo(np.float32).eps.item()\n",
    "\n",
    "optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0007, clipnorm=0.5)\n",
    "num_actions = env.action_space.shape[0]\n",
    "num_hidden_units = 256\n",
    "model = RecurrentActorCritic(num_actions, num_hidden_units)\n",
    "\n",
    "log_dir = get_next_run(LOGS) \n",
    "print('Saving logs to: ', log_dir)\n",
    "summary_writer = tf.summary.create_file_writer(logdir = log_dir)\n",
    "agent2 = RecurrentAgent(0.99, 0.0, 0.4, 8, model, optimizer, summary_writer, debug=True)\n",
    "\n",
    "NUM_EPISODES=100\n",
    "train(agent2, env, NUM_EPISODES, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 1\n",
    "env = gym.make('LunarLanderContinuous-v2')\n",
    "\n",
    "for i in range(num_episodes):\n",
    "    state, _ = env.reset(seed = seed)\n",
    "    done = False\n",
    "    step = 0\n",
    "    while not done:\n",
    "        action = agent2.get_action(state, step)\n",
    "        next_state, reward, terminated, truncated, info = env.step(np.array(action))\n",
    "        done = terminated or truncated\n",
    "        agent2.log(action, state, next_state, reward, done, step)\n",
    "        state = next_state\n",
    "\n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states before prep: [186   8]\n",
      "states after prep: [186   8   8]\n"
     ]
    }
   ],
   "source": [
    "agent2.update(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = agent2.memory['state'].gather([i for i in tf.range(agent.memory['state'].size())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_size = np.max([0, self.window_size-tf.shape(combined_states)[0]], axis = 0)\n",
    "tf.pad(states[i], [[0,np.max([0, self.window_size-i], axis = 0)],[0,0]]) for i in tf.range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8,), dtype=float32, numpy=\n",
       "array([ 0.00442362,  1.4254959 ,  0.21411863,  0.32733026, -0.00409935,\n",
       "       -0.02889132,  0.        ,  0.        ], dtype=float32)>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 9, 8), dtype=float32, numpy=\n",
       "array([[[ 0.00442362,  1.4254959 ,  0.21411863,  0.32733026,\n",
       "         -0.00409935, -0.02889132,  0.        ,  0.        ],\n",
       "        [ 0.76255953,  0.22457801,  1.5824549 , -1.438667  ,\n",
       "         -1.4822356 , -0.53626955,  0.        ,  0.        ],\n",
       "        [ 0.7790512 ,  0.19222791,  1.6510906 , -1.4542502 ,\n",
       "         -1.506693  , -0.48915023,  0.        ,  0.        ],\n",
       "        [ 0.7955519 ,  0.15916143,  1.6515049 , -1.4878939 ,\n",
       "         -1.5337818 , -0.5417758 ,  0.        ,  0.        ],\n",
       "        [ 0.8124922 ,  0.12568003,  1.694713  , -1.5066842 ,\n",
       "         -1.5613644 , -0.55165184,  0.        ,  0.        ],\n",
       "        [ 0.82943994,  0.09152406,  1.6946552 , -1.5378029 ,\n",
       "         -1.590625  , -0.5852125 ,  0.        ,  0.        ],\n",
       "        [ 0.8463917 ,  0.05668946,  1.6940836 , -1.5691475 ,\n",
       "         -1.6216508 , -0.62051594,  0.        ,  0.        ],\n",
       "        [ 0.8639492 ,  0.02130125,  1.7537113 , -1.593907  ,\n",
       "         -1.6529601 , -0.626186  ,  0.        ,  0.        ],\n",
       "        [ 0.8818876 , -0.01470336,  1.7910448 , -1.6197287 ,\n",
       "         -1.6820021 , -0.5808389 ,  0.        ,  0.        ]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent2._pad_input(states[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad_size = np.max([0, self.window_size-tf.shape(combined_states)[0]], axis = 0)\n",
    "\n",
    "initial_padded_states = tf.convert_to_tensor([tf.pad(states[:(i+1)][::-1], [[0,np.max([0, agent2.window_size-(i+1)], axis = 0)],[0,0]]) for i in tf.range(0, agent2.window_size)])\n",
    "remaining_states = tf.convert_to_tensor([states[(i-agent2.window_size):i] for i in tf.range(agent2.window_size, tf.shape(states)[0])])\n",
    "combined_states = tf.concat([initial_padded_states, remaining_states], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(165, 8, 8), dtype=float32, numpy=\n",
       "array([[[ 2.2970201e-03,  1.4181306e+00,  2.3264711e-01, ...,\n",
       "         -5.2698046e-02,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        ...,\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00]],\n",
       "\n",
       "       [[ 4.4236183e-03,  1.4254959e+00,  2.1411863e-01, ...,\n",
       "         -2.8891325e-02,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 2.2970201e-03,  1.4181306e+00,  2.3264711e-01, ...,\n",
       "         -5.2698046e-02,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        ...,\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00]],\n",
       "\n",
       "       [[ 6.5270425e-03,  1.4330266e+00,  2.1036837e-01, ...,\n",
       "         -4.2330031e-04,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 4.4236183e-03,  1.4254959e+00,  2.1411863e-01, ...,\n",
       "         -2.8891325e-02,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 2.2970201e-03,  1.4181306e+00,  2.3264711e-01, ...,\n",
       "         -5.2698046e-02,  0.0000000e+00,  0.0000000e+00],\n",
       "        ...,\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 8.0134487e-01,  4.8145962e-01,  1.7384742e+00, ...,\n",
       "         -5.7951337e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 8.1917632e-01,  4.5359904e-01,  1.7876852e+00, ...,\n",
       "         -5.7677221e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 8.3779085e-01,  4.2519137e-01,  1.8653843e+00, ...,\n",
       "         -6.1862481e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        ...,\n",
       "        [ 8.9545649e-01,  3.3704454e-01,  1.9244627e+00, ...,\n",
       "         -6.2630904e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 9.1492331e-01,  3.0645683e-01,  1.9467871e+00, ...,\n",
       "         -5.9562534e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 9.3439233e-01,  2.7517077e-01,  1.9460510e+00, ...,\n",
       "         -6.3981903e-01,  0.0000000e+00,  0.0000000e+00]],\n",
       "\n",
       "       [[ 8.1917632e-01,  4.5359904e-01,  1.7876852e+00, ...,\n",
       "         -5.7677221e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 8.3779085e-01,  4.2519137e-01,  1.8653843e+00, ...,\n",
       "         -6.1862481e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 8.5700417e-01,  3.9636979e-01,  1.9243157e+00, ...,\n",
       "         -6.2399101e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        ...,\n",
       "        [ 9.1492331e-01,  3.0645683e-01,  1.9467871e+00, ...,\n",
       "         -5.9562534e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 9.3439233e-01,  2.7517077e-01,  1.9460510e+00, ...,\n",
       "         -6.3981903e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 9.5423925e-01,  2.4304004e-01,  1.9828390e+00, ...,\n",
       "         -6.2625843e-01,  0.0000000e+00,  0.0000000e+00]],\n",
       "\n",
       "       [[ 8.3779085e-01,  4.2519137e-01,  1.8653843e+00, ...,\n",
       "         -6.1862481e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 8.5700417e-01,  3.9636979e-01,  1.9243157e+00, ...,\n",
       "         -6.2399101e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 8.7622279e-01,  3.6706960e-01,  1.9237162e+00, ...,\n",
       "         -5.6975877e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        ...,\n",
       "        [ 9.3439233e-01,  2.7517077e-01,  1.9460510e+00, ...,\n",
       "         -6.3981903e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 9.5423925e-01,  2.4304004e-01,  1.9828390e+00, ...,\n",
       "         -6.2625843e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 9.7409457e-01,  2.1030845e-01,  1.9827158e+00, ...,\n",
       "         -6.2621605e-01,  0.0000000e+00,  0.0000000e+00]]], dtype=float32)>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(165, 8, 8), dtype=float32, numpy=\n",
       "array([[[ 2.2970201e-03,  1.4181306e+00,  2.3264711e-01, ...,\n",
       "         -5.2698046e-02,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        ...,\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00]],\n",
       "\n",
       "       [[ 4.4236183e-03,  1.4254959e+00,  2.1411863e-01, ...,\n",
       "         -2.8891325e-02,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 2.2970201e-03,  1.4181306e+00,  2.3264711e-01, ...,\n",
       "         -5.2698046e-02,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        ...,\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00]],\n",
       "\n",
       "       [[ 6.5270425e-03,  1.4330266e+00,  2.1036837e-01, ...,\n",
       "         -4.2330031e-04,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 4.4236183e-03,  1.4254959e+00,  2.1411863e-01, ...,\n",
       "         -2.8891325e-02,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 2.2970201e-03,  1.4181306e+00,  2.3264711e-01, ...,\n",
       "         -5.2698046e-02,  0.0000000e+00,  0.0000000e+00],\n",
       "        ...,\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 8.0134487e-01,  4.8145962e-01,  1.7384742e+00, ...,\n",
       "         -5.7951337e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 8.1917632e-01,  4.5359904e-01,  1.7876852e+00, ...,\n",
       "         -5.7677221e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 8.3779085e-01,  4.2519137e-01,  1.8653843e+00, ...,\n",
       "         -6.1862481e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        ...,\n",
       "        [ 8.9545649e-01,  3.3704454e-01,  1.9244627e+00, ...,\n",
       "         -6.2630904e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 9.1492331e-01,  3.0645683e-01,  1.9467871e+00, ...,\n",
       "         -5.9562534e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 9.3439233e-01,  2.7517077e-01,  1.9460510e+00, ...,\n",
       "         -6.3981903e-01,  0.0000000e+00,  0.0000000e+00]],\n",
       "\n",
       "       [[ 8.1917632e-01,  4.5359904e-01,  1.7876852e+00, ...,\n",
       "         -5.7677221e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 8.3779085e-01,  4.2519137e-01,  1.8653843e+00, ...,\n",
       "         -6.1862481e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 8.5700417e-01,  3.9636979e-01,  1.9243157e+00, ...,\n",
       "         -6.2399101e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        ...,\n",
       "        [ 9.1492331e-01,  3.0645683e-01,  1.9467871e+00, ...,\n",
       "         -5.9562534e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 9.3439233e-01,  2.7517077e-01,  1.9460510e+00, ...,\n",
       "         -6.3981903e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 9.5423925e-01,  2.4304004e-01,  1.9828390e+00, ...,\n",
       "         -6.2625843e-01,  0.0000000e+00,  0.0000000e+00]],\n",
       "\n",
       "       [[ 8.3779085e-01,  4.2519137e-01,  1.8653843e+00, ...,\n",
       "         -6.1862481e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 8.5700417e-01,  3.9636979e-01,  1.9243157e+00, ...,\n",
       "         -6.2399101e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 8.7622279e-01,  3.6706960e-01,  1.9237162e+00, ...,\n",
       "         -5.6975877e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        ...,\n",
       "        [ 9.3439233e-01,  2.7517077e-01,  1.9460510e+00, ...,\n",
       "         -6.3981903e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 9.5423925e-01,  2.4304004e-01,  1.9828390e+00, ...,\n",
       "         -6.2625843e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 9.7409457e-01,  2.1030845e-01,  1.9827158e+00, ...,\n",
       "         -6.2621605e-01,  0.0000000e+00,  0.0000000e+00]]], dtype=float32)>"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat([initial_padded_states, remaining_states], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([8 8 8], shape=(3,), dtype=int32) tf.Tensor([157   8   8], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.shape(initial_padded_states), tf.shape(remaining_states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(8, 1, 9, 8), dtype=float32, numpy=\n",
       "array([[[[ 2.2970201e-03,  1.4181306e+00,  2.3264711e-01,\n",
       "           3.2046661e-01, -2.6548801e-03, -5.2698046e-02,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 7.6255953e-01,  2.2457801e-01,  1.5824549e+00,\n",
       "          -1.4386671e+00, -1.4822356e+00, -5.3626955e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 7.7905118e-01,  1.9222791e-01,  1.6510906e+00,\n",
       "          -1.4542502e+00, -1.5066930e+00, -4.8915023e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 7.9555190e-01,  1.5916143e-01,  1.6515049e+00,\n",
       "          -1.4878939e+00, -1.5337818e+00, -5.4177582e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.1249219e-01,  1.2568003e-01,  1.6947130e+00,\n",
       "          -1.5066842e+00, -1.5613644e+00, -5.5165184e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.2943994e-01,  9.1524065e-02,  1.6946552e+00,\n",
       "          -1.5378029e+00, -1.5906250e+00, -5.8521253e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.4639168e-01,  5.6689464e-02,  1.6940836e+00,\n",
       "          -1.5691475e+00, -1.6216508e+00, -6.2051594e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.6394918e-01,  2.1301255e-02,  1.7537113e+00,\n",
       "          -1.5939070e+00, -1.6529601e+00, -6.2618601e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.8188761e-01, -1.4703359e-02,  1.7910448e+00,\n",
       "          -1.6197287e+00, -1.6820021e+00, -5.8083892e-01,\n",
       "           0.0000000e+00,  0.0000000e+00]]],\n",
       "\n",
       "\n",
       "       [[[ 4.4236183e-03,  1.4254959e+00,  2.1411863e-01,\n",
       "           3.2733026e-01, -4.0993472e-03, -2.8891325e-02,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 7.6255953e-01,  2.2457801e-01,  1.5824549e+00,\n",
       "          -1.4386671e+00, -1.4822356e+00, -5.3626955e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 7.7905118e-01,  1.9222791e-01,  1.6510906e+00,\n",
       "          -1.4542502e+00, -1.5066930e+00, -4.8915023e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 7.9555190e-01,  1.5916143e-01,  1.6515049e+00,\n",
       "          -1.4878939e+00, -1.5337818e+00, -5.4177582e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.1249219e-01,  1.2568003e-01,  1.6947130e+00,\n",
       "          -1.5066842e+00, -1.5613644e+00, -5.5165184e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.2943994e-01,  9.1524065e-02,  1.6946552e+00,\n",
       "          -1.5378029e+00, -1.5906250e+00, -5.8521253e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.4639168e-01,  5.6689464e-02,  1.6940836e+00,\n",
       "          -1.5691475e+00, -1.6216508e+00, -6.2051594e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.6394918e-01,  2.1301255e-02,  1.7537113e+00,\n",
       "          -1.5939070e+00, -1.6529601e+00, -6.2618601e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.8188761e-01, -1.4703359e-02,  1.7910448e+00,\n",
       "          -1.6197287e+00, -1.6820021e+00, -5.8083892e-01,\n",
       "           0.0000000e+00,  0.0000000e+00]]],\n",
       "\n",
       "\n",
       "       [[[ 6.5270425e-03,  1.4330266e+00,  2.1036837e-01,\n",
       "           3.3469948e-01, -4.1205068e-03, -4.2330031e-04,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 7.6255953e-01,  2.2457801e-01,  1.5824549e+00,\n",
       "          -1.4386671e+00, -1.4822356e+00, -5.3626955e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 7.7905118e-01,  1.9222791e-01,  1.6510906e+00,\n",
       "          -1.4542502e+00, -1.5066930e+00, -4.8915023e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 7.9555190e-01,  1.5916143e-01,  1.6515049e+00,\n",
       "          -1.4878939e+00, -1.5337818e+00, -5.4177582e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.1249219e-01,  1.2568003e-01,  1.6947130e+00,\n",
       "          -1.5066842e+00, -1.5613644e+00, -5.5165184e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.2943994e-01,  9.1524065e-02,  1.6946552e+00,\n",
       "          -1.5378029e+00, -1.5906250e+00, -5.8521253e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.4639168e-01,  5.6689464e-02,  1.6940836e+00,\n",
       "          -1.5691475e+00, -1.6216508e+00, -6.2051594e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.6394918e-01,  2.1301255e-02,  1.7537113e+00,\n",
       "          -1.5939070e+00, -1.6529601e+00, -6.2618601e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.8188761e-01, -1.4703359e-02,  1.7910448e+00,\n",
       "          -1.6197287e+00, -1.6820021e+00, -5.8083892e-01,\n",
       "           0.0000000e+00,  0.0000000e+00]]],\n",
       "\n",
       "\n",
       "       [[[ 8.6305616e-03,  1.4399571e+00,  2.1036811e-01,\n",
       "           3.0802506e-01, -4.1422374e-03, -4.3441285e-04,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 7.6255953e-01,  2.2457801e-01,  1.5824549e+00,\n",
       "          -1.4386671e+00, -1.4822356e+00, -5.3626955e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 7.7905118e-01,  1.9222791e-01,  1.6510906e+00,\n",
       "          -1.4542502e+00, -1.5066930e+00, -4.8915023e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 7.9555190e-01,  1.5916143e-01,  1.6515049e+00,\n",
       "          -1.4878939e+00, -1.5337818e+00, -5.4177582e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.1249219e-01,  1.2568003e-01,  1.6947130e+00,\n",
       "          -1.5066842e+00, -1.5613644e+00, -5.5165184e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.2943994e-01,  9.1524065e-02,  1.6946552e+00,\n",
       "          -1.5378029e+00, -1.5906250e+00, -5.8521253e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.4639168e-01,  5.6689464e-02,  1.6940836e+00,\n",
       "          -1.5691475e+00, -1.6216508e+00, -6.2051594e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.6394918e-01,  2.1301255e-02,  1.7537113e+00,\n",
       "          -1.5939070e+00, -1.6529601e+00, -6.2618601e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.8188761e-01, -1.4703359e-02,  1.7910448e+00,\n",
       "          -1.6197287e+00, -1.6820021e+00, -5.8083892e-01,\n",
       "           0.0000000e+00,  0.0000000e+00]]],\n",
       "\n",
       "\n",
       "       [[[ 1.0851001e-02,  1.4475058e+00,  2.2151287e-01,\n",
       "           3.3550274e-01, -3.6195451e-03,  1.0454694e-02,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 7.6255953e-01,  2.2457801e-01,  1.5824549e+00,\n",
       "          -1.4386671e+00, -1.4822356e+00, -5.3626955e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 7.7905118e-01,  1.9222791e-01,  1.6510906e+00,\n",
       "          -1.4542502e+00, -1.5066930e+00, -4.8915023e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 7.9555190e-01,  1.5916143e-01,  1.6515049e+00,\n",
       "          -1.4878939e+00, -1.5337818e+00, -5.4177582e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.1249219e-01,  1.2568003e-01,  1.6947130e+00,\n",
       "          -1.5066842e+00, -1.5613644e+00, -5.5165184e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.2943994e-01,  9.1524065e-02,  1.6946552e+00,\n",
       "          -1.5378029e+00, -1.5906250e+00, -5.8521253e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.4639168e-01,  5.6689464e-02,  1.6940836e+00,\n",
       "          -1.5691475e+00, -1.6216508e+00, -6.2051594e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.6394918e-01,  2.1301255e-02,  1.7537113e+00,\n",
       "          -1.5939070e+00, -1.6529601e+00, -6.2618601e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.8188761e-01, -1.4703359e-02,  1.7910448e+00,\n",
       "          -1.6197287e+00, -1.6820021e+00, -5.8083892e-01,\n",
       "           0.0000000e+00,  0.0000000e+00]]],\n",
       "\n",
       "\n",
       "       [[[ 1.2963104e-02,  1.4551401e+00,  2.0961066e-01,\n",
       "           3.3930641e-01, -2.0312609e-03,  3.1768553e-02,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 7.6255953e-01,  2.2457801e-01,  1.5824549e+00,\n",
       "          -1.4386671e+00, -1.4822356e+00, -5.3626955e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 7.7905118e-01,  1.9222791e-01,  1.6510906e+00,\n",
       "          -1.4542502e+00, -1.5066930e+00, -4.8915023e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 7.9555190e-01,  1.5916143e-01,  1.6515049e+00,\n",
       "          -1.4878939e+00, -1.5337818e+00, -5.4177582e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.1249219e-01,  1.2568003e-01,  1.6947130e+00,\n",
       "          -1.5066842e+00, -1.5613644e+00, -5.5165184e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.2943994e-01,  9.1524065e-02,  1.6946552e+00,\n",
       "          -1.5378029e+00, -1.5906250e+00, -5.8521253e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.4639168e-01,  5.6689464e-02,  1.6940836e+00,\n",
       "          -1.5691475e+00, -1.6216508e+00, -6.2051594e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.6394918e-01,  2.1301255e-02,  1.7537113e+00,\n",
       "          -1.5939070e+00, -1.6529601e+00, -6.2618601e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.8188761e-01, -1.4703359e-02,  1.7910448e+00,\n",
       "          -1.6197287e+00, -1.6820021e+00, -5.8083892e-01,\n",
       "           0.0000000e+00,  0.0000000e+00]]],\n",
       "\n",
       "\n",
       "       [[[ 1.4989471e-02,  1.4627008e+00,  2.0144220e-01,\n",
       "           3.3603105e-01, -8.5624080e-04,  2.3502791e-02,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 7.6255953e-01,  2.2457801e-01,  1.5824549e+00,\n",
       "          -1.4386671e+00, -1.4822356e+00, -5.3626955e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 7.7905118e-01,  1.9222791e-01,  1.6510906e+00,\n",
       "          -1.4542502e+00, -1.5066930e+00, -4.8915023e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 7.9555190e-01,  1.5916143e-01,  1.6515049e+00,\n",
       "          -1.4878939e+00, -1.5337818e+00, -5.4177582e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.1249219e-01,  1.2568003e-01,  1.6947130e+00,\n",
       "          -1.5066842e+00, -1.5613644e+00, -5.5165184e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.2943994e-01,  9.1524065e-02,  1.6946552e+00,\n",
       "          -1.5378029e+00, -1.5906250e+00, -5.8521253e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.4639168e-01,  5.6689464e-02,  1.6940836e+00,\n",
       "          -1.5691475e+00, -1.6216508e+00, -6.2051594e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.6394918e-01,  2.1301255e-02,  1.7537113e+00,\n",
       "          -1.5939070e+00, -1.6529601e+00, -6.2618601e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.8188761e-01, -1.4703359e-02,  1.7910448e+00,\n",
       "          -1.6197287e+00, -1.6820021e+00, -5.8083892e-01,\n",
       "           0.0000000e+00,  0.0000000e+00]]],\n",
       "\n",
       "\n",
       "       [[[ 1.6954422e-02,  1.4696544e+00,  1.9374615e-01,\n",
       "           3.0904675e-01,  1.8613287e-03,  5.4356296e-02,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 7.6255953e-01,  2.2457801e-01,  1.5824549e+00,\n",
       "          -1.4386671e+00, -1.4822356e+00, -5.3626955e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 7.7905118e-01,  1.9222791e-01,  1.6510906e+00,\n",
       "          -1.4542502e+00, -1.5066930e+00, -4.8915023e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 7.9555190e-01,  1.5916143e-01,  1.6515049e+00,\n",
       "          -1.4878939e+00, -1.5337818e+00, -5.4177582e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.1249219e-01,  1.2568003e-01,  1.6947130e+00,\n",
       "          -1.5066842e+00, -1.5613644e+00, -5.5165184e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.2943994e-01,  9.1524065e-02,  1.6946552e+00,\n",
       "          -1.5378029e+00, -1.5906250e+00, -5.8521253e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.4639168e-01,  5.6689464e-02,  1.6940836e+00,\n",
       "          -1.5691475e+00, -1.6216508e+00, -6.2051594e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.6394918e-01,  2.1301255e-02,  1.7537113e+00,\n",
       "          -1.5939070e+00, -1.6529601e+00, -6.2618601e-01,\n",
       "           0.0000000e+00,  0.0000000e+00],\n",
       "         [ 8.8188761e-01, -1.4703359e-02,  1.7910448e+00,\n",
       "          -1.6197287e+00, -1.6820021e+00, -5.8083892e-01,\n",
       "           0.0000000e+00,  0.0000000e+00]]]], dtype=float32)>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_padded_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "states before prep: [152   8]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Ranks of all input tensors should match: shape[0] = [8,1,9,8] vs. shape[1] = [144,8,8] [Op:ConcatV2] name: concat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\61417\\Documents\\Units\\thesis_preparation\\right_left_brain_rl\\experiment\\working\\learn_tensorflow\\learning_tensorflow_RL_continuous.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_continuous.ipynb#Y160sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m agent2\u001b[39m.\u001b[39;49mupdate(i)\n",
      "\u001b[1;32mc:\\Users\\61417\\Documents\\Units\\thesis_preparation\\right_left_brain_rl\\experiment\\working\\learn_tensorflow\\learning_tensorflow_RL_continuous.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_continuous.ipynb#Y160sZmlsZQ%3D%3D?line=159'>160</a>\u001b[0m states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory[\u001b[39m'\u001b[39m\u001b[39mstate\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mgather([i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mrange(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory[\u001b[39m'\u001b[39m\u001b[39mstate\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msize())])\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_continuous.ipynb#Y160sZmlsZQ%3D%3D?line=160'>161</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstates before prep: \u001b[39m\u001b[39m{\u001b[39;00mtf\u001b[39m.\u001b[39mshape(states)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_continuous.ipynb#Y160sZmlsZQ%3D%3D?line=161'>162</a>\u001b[0m states \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_states_for_lstm(states)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_continuous.ipynb#Y160sZmlsZQ%3D%3D?line=162'>163</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstates after prep: \u001b[39m\u001b[39m{\u001b[39;00mtf\u001b[39m.\u001b[39mshape(states)\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_continuous.ipynb#Y160sZmlsZQ%3D%3D?line=163'>164</a>\u001b[0m rewards \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory[\u001b[39m'\u001b[39m\u001b[39mrewards\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mgather([i \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mrange(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory[\u001b[39m'\u001b[39m\u001b[39mrewards\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39msize())])\n",
      "\u001b[1;32mc:\\Users\\61417\\Documents\\Units\\thesis_preparation\\right_left_brain_rl\\experiment\\working\\learn_tensorflow\\learning_tensorflow_RL_continuous.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_continuous.ipynb#Y160sZmlsZQ%3D%3D?line=150'>151</a>\u001b[0m initial_padded_states \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconvert_to_tensor([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pad_input(states[i]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mrange(\u001b[39m0\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow_size)])\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_continuous.ipynb#Y160sZmlsZQ%3D%3D?line=151'>152</a>\u001b[0m remaining_states \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconvert_to_tensor([states[(i\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow_size):i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mrange(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwindow_size, tf\u001b[39m.\u001b[39mshape(states)[\u001b[39m0\u001b[39m])])\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_continuous.ipynb#Y160sZmlsZQ%3D%3D?line=152'>153</a>\u001b[0m combined_states \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mconcat([initial_padded_states, remaining_states], axis \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_continuous.ipynb#Y160sZmlsZQ%3D%3D?line=154'>155</a>\u001b[0m \u001b[39mreturn\u001b[39;00m combined_states\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\framework\\ops.py:5888\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   5886\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NoReturn:\n\u001b[0;32m   5887\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m-> 5888\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__ConcatV2_N_2_device_/job:localhost/replica:0/task:0/device:CPU:0}} ConcatOp : Ranks of all input tensors should match: shape[0] = [8,1,9,8] vs. shape[1] = [144,8,8] [Op:ConcatV2] name: concat"
     ]
    }
   ],
   "source": [
    "agent2.update(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I need to roll actions, states and rewards into batches so\n",
    "# batch_size x timesteps x 3\n",
    "actions = agent.memory['action'].gather([i for i in tf.range(agent.memory['action'].size())])\n",
    "states = agent.memory['state'].gather([i for i in tf.range(agent.memory['state'].size())])\n",
    "rewards = agent.memory['rewards'].gather([i for i in tf.range(agent.memory['rewards'].size())])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([-0.8053639, -0.5151801], dtype=float32)>"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(165, 8), dtype=float32, numpy=\n",
       "array([[ 2.2970201e-03,  1.4181306e+00,  2.3264711e-01, ...,\n",
       "        -5.2698046e-02,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 4.4236183e-03,  1.4254959e+00,  2.1411863e-01, ...,\n",
       "        -2.8891325e-02,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 6.5270425e-03,  1.4330266e+00,  2.1036837e-01, ...,\n",
       "        -4.2330031e-04,  0.0000000e+00,  0.0000000e+00],\n",
       "       ...,\n",
       "       [ 9.5423925e-01,  2.4304004e-01,  1.9828390e+00, ...,\n",
       "        -6.2625843e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 9.7409457e-01,  2.1030845e-01,  1.9827158e+00, ...,\n",
       "        -6.2621605e-01,  0.0000000e+00,  0.0000000e+00],\n",
       "       [ 9.9395734e-01,  1.7691380e-01,  1.9822598e+00, ...,\n",
       "        -6.5380037e-01,  0.0000000e+00,  0.0000000e+00]], dtype=float32)>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[ 0.02998333  0.02727829 -0.2577023  -1.9478024   2.714047    0.42441875\n",
      "  0.          0.        ], shape=(8,), dtype=float32) tf.Tensor(\n",
      "[[ 0.03765373  0.15462822 -0.19136551 -1.8191761   2.6443205   0.54569924\n",
      "   0.          0.        ]\n",
      " [ 0.035429    0.1133526  -0.1999444  -1.8424113   2.6694772   0.5031384\n",
      "   0.          0.        ]], shape=(2, 8), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "new_state =states[-1]\n",
    "prev_states = states[-4:-2]\n",
    "print(new_state, prev_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 5, 8), dtype=float32, numpy=\n",
       "array([[[ 0.02998333,  0.02727829, -0.2577023 , -1.9478024 ,\n",
       "          2.714047  ,  0.42441875,  0.        ,  0.        ],\n",
       "        [ 0.03765373,  0.15462822, -0.19136551, -1.8191761 ,\n",
       "          2.6443205 ,  0.54569924,  0.        ,  0.        ],\n",
       "        [ 0.035429  ,  0.1133526 , -0.1999444 , -1.8424113 ,\n",
       "          2.6694772 ,  0.5031384 ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        ,  0.        ,  0.        ,  0.        ]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "combined_states = tf.concat([tf.expand_dims(new_state, 0), prev_states], axis =0)\n",
    "padded = tf.pad(combined_states, [[0,np.max([0,window_size - tf.shape(combined_states)[0]],axis=0)],[0,0]])\n",
    "tf.expand_dims(padded, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=3>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape(combined_states)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max([0,window_size - tf.shape(combined_states)[0]],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = tf.keras.Sequential(\n",
    "    layers.LSTM(2)\n",
    ")\n",
    "window_size = 5\n",
    "\n",
    "inputs = tf.convert_to_tensor([tf.concat([actions[(i-window_size):i], states[(i-window_size):i], tf.expand_dims(rewards[(i-window_size):i], 1)], axis = 1) for i in tf.range(window_size, tf.shape(actions)[0])])\n",
    "outputs = lstm(inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=3>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "window_size - tf.shape(tensor1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([76  5 11], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "tensor1 = inputs[:,0:10,:]#tf.constant([[[1,2,3], [4,5,6], [9,9,9]],[[1,2,3], [4,5,6], [9,9,9]]])\n",
    "pad_tensor1 = tf.pad(tensor1, [[0,0],[0,np.max([0,window_size - tf.shape(tensor1)[1]],axis=0)],[0,0]])\n",
    "print(tf.shape(pad_tensor1))\n",
    "# window_size - tf.shape(tensor1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(76, 5, 11), dtype=float32, numpy=\n",
       "array([[[-9.9999952e-01, -2.1917503e-01,  2.2970201e-03, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  1.1449804e+00],\n",
       "        [-9.9975705e-01,  2.1055248e-01,  4.5939446e-03, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  1.1880542e+00],\n",
       "        [-9.9997276e-01, -7.9044843e-01,  6.8910597e-03, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  1.8632145e+00],\n",
       "        [-9.9999756e-01, -4.1611990e-01,  9.1216089e-03, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  1.3250611e+00],\n",
       "        [-9.9999225e-01,  4.8514101e-01,  1.1352062e-02, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  1.2652316e+00]],\n",
       "\n",
       "       [[-9.9975705e-01,  2.1055248e-01,  4.5939446e-03, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  1.1880542e+00],\n",
       "        [-9.9997276e-01, -7.9044843e-01,  6.8910597e-03, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  1.8632145e+00],\n",
       "        [-9.9999756e-01, -4.1611990e-01,  9.1216089e-03, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  1.3250611e+00],\n",
       "        [-9.9999225e-01,  4.8514101e-01,  1.1352062e-02, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  1.2652316e+00],\n",
       "        [-9.9999970e-01, -9.0854186e-01,  1.3582611e-02, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  2.2584732e+00]],\n",
       "\n",
       "       [[-9.9997276e-01, -7.9044843e-01,  6.8910597e-03, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  1.8632145e+00],\n",
       "        [-9.9999756e-01, -4.1611990e-01,  9.1216089e-03, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  1.3250611e+00],\n",
       "        [-9.9999225e-01,  4.8514101e-01,  1.1352062e-02, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  1.2652316e+00],\n",
       "        [-9.9999970e-01, -9.0854186e-01,  1.3582611e-02, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  2.2584732e+00],\n",
       "        [-1.0000000e+00, -5.1260000e-01,  1.5725423e-02, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  1.8191267e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-3.1640351e-01,  9.2253917e-01,  4.4707872e-02, ...,\n",
       "          0.0000000e+00,  0.0000000e+00, -2.0015001e+00],\n",
       "        [ 5.8827847e-01,  8.1175488e-01,  4.3474007e-02, ...,\n",
       "          0.0000000e+00,  0.0000000e+00, -5.5305185e+00],\n",
       "        [ 4.5855010e-01,  9.2187142e-01,  4.1893102e-02, ...,\n",
       "          0.0000000e+00,  0.0000000e+00, -5.5205545e+00],\n",
       "        [-9.3630381e-02,  8.1635225e-01,  3.9808273e-02, ...,\n",
       "          0.0000000e+00,  0.0000000e+00, -1.1190656e+00],\n",
       "        [-1.1913704e-01,  9.9739420e-01,  3.7653733e-02, ...,\n",
       "          0.0000000e+00,  0.0000000e+00, -9.0847999e-01]],\n",
       "\n",
       "       [[ 5.8827847e-01,  8.1175488e-01,  4.3474007e-02, ...,\n",
       "          0.0000000e+00,  0.0000000e+00, -5.5305185e+00],\n",
       "        [ 4.5855010e-01,  9.2187142e-01,  4.1893102e-02, ...,\n",
       "          0.0000000e+00,  0.0000000e+00, -5.5205545e+00],\n",
       "        [-9.3630381e-02,  8.1635225e-01,  3.9808273e-02, ...,\n",
       "          0.0000000e+00,  0.0000000e+00, -1.1190656e+00],\n",
       "        [-1.1913704e-01,  9.9739420e-01,  3.7653733e-02, ...,\n",
       "          0.0000000e+00,  0.0000000e+00, -9.0847999e-01],\n",
       "        [ 9.1442662e-01,  9.7914964e-01,  3.5429001e-02, ...,\n",
       "          0.0000000e+00,  0.0000000e+00, -3.9493604e+00]],\n",
       "\n",
       "       [[ 4.5855010e-01,  9.2187142e-01,  4.1893102e-02, ...,\n",
       "          0.0000000e+00,  0.0000000e+00, -5.5205545e+00],\n",
       "        [-9.3630381e-02,  8.1635225e-01,  3.9808273e-02, ...,\n",
       "          0.0000000e+00,  0.0000000e+00, -1.1190656e+00],\n",
       "        [-1.1913704e-01,  9.9739420e-01,  3.7653733e-02, ...,\n",
       "          0.0000000e+00,  0.0000000e+00, -9.0847999e-01],\n",
       "        [ 9.1442662e-01,  9.7914964e-01,  3.5429001e-02, ...,\n",
       "          0.0000000e+00,  0.0000000e+00, -3.9493604e+00],\n",
       "        [ 9.9929965e-01,  8.3843160e-01,  3.2754995e-02, ...,\n",
       "          0.0000000e+00,  0.0000000e+00, -4.4814076e+00]]], dtype=float32)>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(76, 6, 11), dtype=float32, numpy=\n",
       "array([[[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [-9.9975705e-01,  2.1055248e-01,  4.5939446e-03, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  1.1880542e+00],\n",
       "        [-9.9997276e-01, -7.9044843e-01,  6.8910597e-03, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  1.8632145e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00]],\n",
       "\n",
       "       [[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [-9.9997276e-01, -7.9044843e-01,  6.8910597e-03, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  1.8632145e+00],\n",
       "        [-9.9999756e-01, -4.1611990e-01,  9.1216089e-03, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  1.3250611e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00]],\n",
       "\n",
       "       [[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [-9.9999756e-01, -4.1611990e-01,  9.1216089e-03, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  1.3250611e+00],\n",
       "        [-9.9999225e-01,  4.8514101e-01,  1.1352062e-02, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  1.2652316e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 5.8827847e-01,  8.1175488e-01,  4.3474007e-02, ...,\n",
       "          0.0000000e+00,  0.0000000e+00, -5.5305185e+00],\n",
       "        [ 4.5855010e-01,  9.2187142e-01,  4.1893102e-02, ...,\n",
       "          0.0000000e+00,  0.0000000e+00, -5.5205545e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00]],\n",
       "\n",
       "       [[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 4.5855010e-01,  9.2187142e-01,  4.1893102e-02, ...,\n",
       "          0.0000000e+00,  0.0000000e+00, -5.5205545e+00],\n",
       "        [-9.3630381e-02,  8.1635225e-01,  3.9808273e-02, ...,\n",
       "          0.0000000e+00,  0.0000000e+00, -1.1190656e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00]],\n",
       "\n",
       "       [[ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [-9.3630381e-02,  8.1635225e-01,  3.9808273e-02, ...,\n",
       "          0.0000000e+00,  0.0000000e+00, -1.1190656e+00],\n",
       "        [-1.1913704e-01,  9.9739420e-01,  3.7653733e-02, ...,\n",
       "          0.0000000e+00,  0.0000000e+00, -9.0847999e-01],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00],\n",
       "        [ 0.0000000e+00,  0.0000000e+00,  0.0000000e+00, ...,\n",
       "          0.0000000e+00,  0.0000000e+00,  0.0000000e+00]]], dtype=float32)>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_tensor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([133   1  11], shape=(3,), dtype=int32) tf.Tensor([133   1  11], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "examp = tf.expand_dims(inputs[:, 1,:], 1)\n",
    "pad_examp = tf.keras.utils.pad_sequences(examp)\n",
    "print(tf.shape(examp), tf.shape(pad_examp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:CPU:0}} The first dimension of paddings must be the rank of inputs[2,2] [133,1,11] [Op:Pad]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\61417\\Documents\\Units\\thesis_preparation\\right_left_brain_rl\\experiment\\working\\learn_tensorflow\\learning_tensorflow_RL_continuous.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_continuous.ipynb#Y135sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m tf\u001b[39m.\u001b[39;49mpad(examp, paddings\u001b[39m=\u001b[39;49m [[\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m],[\u001b[39m1\u001b[39;49m,\u001b[39m1\u001b[39;49m]],constant_values\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:CPU:0}} The first dimension of paddings must be the rank of inputs[2,2] [133,1,11] [Op:Pad]"
     ]
    }
   ],
   "source": [
    "tf.pad(examp, paddings= [[1,1],[1,1]],constant_values=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Missing required positional argument",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\61417\\Documents\\Units\\thesis_preparation\\right_left_brain_rl\\experiment\\working\\learn_tensorflow\\learning_tensorflow_RL_continuous.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_continuous.ipynb#Y125sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m [tf\u001b[39m.\u001b[39;49mconcat(values \u001b[39m=\u001b[39;49m [actions[(i\u001b[39m-\u001b[39;49mwindow_size):i], states[(i\u001b[39m-\u001b[39;49mwindow_size):i], rewards[(i\u001b[39m-\u001b[39;49mwindow_size):i]]) \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m tf\u001b[39m.\u001b[39;49mrange(window_size, tf\u001b[39m.\u001b[39;49mshape(actions)[\u001b[39m0\u001b[39;49m])]\n",
      "\u001b[1;32mc:\\Users\\61417\\Documents\\Units\\thesis_preparation\\right_left_brain_rl\\experiment\\working\\learn_tensorflow\\learning_tensorflow_RL_continuous.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_continuous.ipynb#Y125sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m [tf\u001b[39m.\u001b[39;49mconcat(values \u001b[39m=\u001b[39;49m [actions[(i\u001b[39m-\u001b[39;49mwindow_size):i], states[(i\u001b[39m-\u001b[39;49mwindow_size):i], rewards[(i\u001b[39m-\u001b[39;49mwindow_size):i]]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mrange(window_size, tf\u001b[39m.\u001b[39mshape(actions)[\u001b[39m0\u001b[39m])]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\dispatch.py:1254\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1252\u001b[0m \u001b[39mif\u001b[39;00m iterable_params \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   1253\u001b[0m   args, kwargs \u001b[39m=\u001b[39m replace_iterable_params(args, kwargs, iterable_params)\n\u001b[1;32m-> 1254\u001b[0m result \u001b[39m=\u001b[39m api_dispatcher\u001b[39m.\u001b[39;49mDispatch(args, kwargs)\n\u001b[0;32m   1255\u001b[0m \u001b[39mif\u001b[39;00m result \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[0;32m   1256\u001b[0m   \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[1;31mTypeError\u001b[0m: Missing required positional argument"
     ]
    }
   ],
   "source": [
    "# so I want to pad inputs during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\61417\\Documents\\Units\\thesis_preparation\\right_left_brain_rl\\experiment\\working\\learn_tensorflow\\learning_tensorflow_RL_continuous.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_continuous.ipynb#Y122sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m reshaped \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconvert_to_tensor([tf\u001b[39m.\u001b[39;49mstack(actions[(i\u001b[39m-\u001b[39;49mwindow_size):i], states[(i\u001b[39m-\u001b[39;49mwindow_size):i],rewards[(i\u001b[39m-\u001b[39;49mwindow_size):i]) \u001b[39mfor\u001b[39;49;00m i \u001b[39min\u001b[39;49;00m tf\u001b[39m.\u001b[39;49mrange(window_size, tf\u001b[39m.\u001b[39;49mshape(actions)[\u001b[39m0\u001b[39;49m])])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_continuous.ipynb#Y122sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m reshaped\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_continuous.ipynb#Y122sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# lstm(reshaped)\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\61417\\Documents\\Units\\thesis_preparation\\right_left_brain_rl\\experiment\\working\\learn_tensorflow\\learning_tensorflow_RL_continuous.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_continuous.ipynb#Y122sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m reshaped \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconvert_to_tensor([tf\u001b[39m.\u001b[39;49mstack(actions[(i\u001b[39m-\u001b[39;49mwindow_size):i], states[(i\u001b[39m-\u001b[39;49mwindow_size):i],rewards[(i\u001b[39m-\u001b[39;49mwindow_size):i]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mrange(window_size, tf\u001b[39m.\u001b[39mshape(actions)[\u001b[39m0\u001b[39m])])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_continuous.ipynb#Y122sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m reshaped\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_continuous.ipynb#Y122sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# lstm(reshaped)\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\framework\\ops.py:302\u001b[0m, in \u001b[0;36m_EagerTensorBase.__bool__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    301\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__bool__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mbool\u001b[39m:\n\u001b[1;32m--> 302\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mbool\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_numpy())\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "reshaped = tf.convert_to_tensor([tf.stack(actions[(i-window_size):i], states[(i-window_size):i],rewards[(i-window_size):i]) for i in tf.range(window_size, tf.shape(actions)[0])])\n",
    "reshaped\n",
    "# lstm(reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 9.2616910e-01  5.6924653e-04]\n",
      " [-5.8331132e-01  9.5472580e-01]\n",
      " [-3.2710966e-01 -8.0249214e-01]\n",
      " [-9.0271854e-01 -2.4973607e-01]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.5833113   0.9547258 ]\n",
      " [-0.32710966 -0.80249214]\n",
      " [-0.90271854 -0.24973607]\n",
      " [ 0.36762196 -0.2197899 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.32710966 -0.80249214]\n",
      " [-0.90271854 -0.24973607]\n",
      " [ 0.36762196 -0.2197899 ]\n",
      " [-0.49681523  0.6425888 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.90271854 -0.24973607]\n",
      " [ 0.36762196 -0.2197899 ]\n",
      " [-0.49681523  0.6425888 ]\n",
      " [-0.3458454  -0.5184323 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.36762196 -0.2197899 ]\n",
      " [-0.49681523  0.6425888 ]\n",
      " [-0.3458454  -0.5184323 ]\n",
      " [-0.8733477  -0.10362962]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.49681523  0.6425888 ]\n",
      " [-0.3458454  -0.5184323 ]\n",
      " [-0.8733477  -0.10362962]\n",
      " [-0.39454803  0.500879  ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.3458454  -0.5184323 ]\n",
      " [-0.8733477  -0.10362962]\n",
      " [-0.39454803  0.500879  ]\n",
      " [ 0.34622034 -0.17023838]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.8733477  -0.10362962]\n",
      " [-0.39454803  0.500879  ]\n",
      " [ 0.34622034 -0.17023838]\n",
      " [-0.8102332   0.20672584]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.39454803  0.500879  ]\n",
      " [ 0.34622034 -0.17023838]\n",
      " [-0.8102332   0.20672584]\n",
      " [ 0.90767443 -0.6328235 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.34622034 -0.17023838]\n",
      " [-0.8102332   0.20672584]\n",
      " [ 0.90767443 -0.6328235 ]\n",
      " [-0.8577537  -0.66248584]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.8102332   0.20672584]\n",
      " [ 0.90767443 -0.6328235 ]\n",
      " [-0.8577537  -0.66248584]\n",
      " [ 0.07359134  0.4457495 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.90767443 -0.6328235 ]\n",
      " [-0.8577537  -0.66248584]\n",
      " [ 0.07359134  0.4457495 ]\n",
      " [-0.86196226 -0.7116381 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.8577537  -0.66248584]\n",
      " [ 0.07359134  0.4457495 ]\n",
      " [-0.86196226 -0.7116381 ]\n",
      " [ 0.8015833  -0.99314845]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.07359134  0.4457495 ]\n",
      " [-0.86196226 -0.7116381 ]\n",
      " [ 0.8015833  -0.99314845]\n",
      " [ 0.706362    0.5090075 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.86196226 -0.7116381 ]\n",
      " [ 0.8015833  -0.99314845]\n",
      " [ 0.706362    0.5090075 ]\n",
      " [ 0.7299795   0.76088166]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.8015833  -0.99314845]\n",
      " [ 0.706362    0.5090075 ]\n",
      " [ 0.7299795   0.76088166]\n",
      " [-0.8435754  -0.02985991]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.706362    0.5090075 ]\n",
      " [ 0.7299795   0.76088166]\n",
      " [-0.8435754  -0.02985991]\n",
      " [-0.9162833  -0.23686212]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.7299795   0.76088166]\n",
      " [-0.8435754  -0.02985991]\n",
      " [-0.9162833  -0.23686212]\n",
      " [ 0.07486542 -0.20628166]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.8435754  -0.02985991]\n",
      " [-0.9162833  -0.23686212]\n",
      " [ 0.07486542 -0.20628166]\n",
      " [-0.3878662   0.7973365 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.9162833  -0.23686212]\n",
      " [ 0.07486542 -0.20628166]\n",
      " [-0.3878662   0.7973365 ]\n",
      " [-0.7749977   0.88668627]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.07486542 -0.20628166]\n",
      " [-0.3878662   0.7973365 ]\n",
      " [-0.7749977   0.88668627]\n",
      " [-0.689183    0.14203423]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.3878662   0.7973365 ]\n",
      " [-0.7749977   0.88668627]\n",
      " [-0.689183    0.14203423]\n",
      " [ 0.31354657 -0.20506233]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.7749977   0.88668627]\n",
      " [-0.689183    0.14203423]\n",
      " [ 0.31354657 -0.20506233]\n",
      " [-0.98266315  0.9523449 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.689183    0.14203423]\n",
      " [ 0.31354657 -0.20506233]\n",
      " [-0.98266315  0.9523449 ]\n",
      " [ 0.73308104  0.69892794]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.31354657 -0.20506233]\n",
      " [-0.98266315  0.9523449 ]\n",
      " [ 0.73308104  0.69892794]\n",
      " [ 0.01908364  0.8141656 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.98266315  0.9523449 ]\n",
      " [ 0.73308104  0.69892794]\n",
      " [ 0.01908364  0.8141656 ]\n",
      " [ 0.38222867 -0.48074493]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.73308104  0.69892794]\n",
      " [ 0.01908364  0.8141656 ]\n",
      " [ 0.38222867 -0.48074493]\n",
      " [ 0.3325228   0.8781505 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.01908364  0.8141656 ]\n",
      " [ 0.38222867 -0.48074493]\n",
      " [ 0.3325228   0.8781505 ]\n",
      " [-0.89554286 -0.87058556]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.38222867 -0.48074493]\n",
      " [ 0.3325228   0.8781505 ]\n",
      " [-0.89554286 -0.87058556]\n",
      " [-0.77920324 -0.8883612 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.3325228   0.8781505 ]\n",
      " [-0.89554286 -0.87058556]\n",
      " [-0.77920324 -0.8883612 ]\n",
      " [-0.8929852  -0.8364558 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.89554286 -0.87058556]\n",
      " [-0.77920324 -0.8883612 ]\n",
      " [-0.8929852  -0.8364558 ]\n",
      " [-0.9032591  -0.3211658 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.77920324 -0.8883612 ]\n",
      " [-0.8929852  -0.8364558 ]\n",
      " [-0.9032591  -0.3211658 ]\n",
      " [-0.66384876 -0.92932403]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.8929852  -0.8364558 ]\n",
      " [-0.9032591  -0.3211658 ]\n",
      " [-0.66384876 -0.92932403]\n",
      " [-0.632369    0.9849753 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.9032591  -0.3211658 ]\n",
      " [-0.66384876 -0.92932403]\n",
      " [-0.632369    0.9849753 ]\n",
      " [-0.28908536  0.8532328 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.66384876 -0.92932403]\n",
      " [-0.632369    0.9849753 ]\n",
      " [-0.28908536  0.8532328 ]\n",
      " [ 0.10617903 -0.3512459 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.632369    0.9849753 ]\n",
      " [-0.28908536  0.8532328 ]\n",
      " [ 0.10617903 -0.3512459 ]\n",
      " [-0.976649   -0.1436362 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.28908536  0.8532328 ]\n",
      " [ 0.10617903 -0.3512459 ]\n",
      " [-0.976649   -0.1436362 ]\n",
      " [ 0.38145489 -0.24734916]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.10617903 -0.3512459 ]\n",
      " [-0.976649   -0.1436362 ]\n",
      " [ 0.38145489 -0.24734916]\n",
      " [ 0.85530025 -0.45333558]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.976649   -0.1436362 ]\n",
      " [ 0.38145489 -0.24734916]\n",
      " [ 0.85530025 -0.45333558]\n",
      " [-0.25341943 -0.8083005 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.38145489 -0.24734916]\n",
      " [ 0.85530025 -0.45333558]\n",
      " [-0.25341943 -0.8083005 ]\n",
      " [ 0.19462384 -0.3939478 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.85530025 -0.45333558]\n",
      " [-0.25341943 -0.8083005 ]\n",
      " [ 0.19462384 -0.3939478 ]\n",
      " [-0.80407876  0.8804543 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.25341943 -0.8083005 ]\n",
      " [ 0.19462384 -0.3939478 ]\n",
      " [-0.80407876  0.8804543 ]\n",
      " [ 0.03273363  0.41433057]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.19462384 -0.3939478 ]\n",
      " [-0.80407876  0.8804543 ]\n",
      " [ 0.03273363  0.41433057]\n",
      " [-0.25519153  0.82159954]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.80407876  0.8804543 ]\n",
      " [ 0.03273363  0.41433057]\n",
      " [-0.25519153  0.82159954]\n",
      " [ 0.98754525 -0.6649405 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.03273363  0.41433057]\n",
      " [-0.25519153  0.82159954]\n",
      " [ 0.98754525 -0.6649405 ]\n",
      " [ 0.6013668  -0.96962893]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.25519153  0.82159954]\n",
      " [ 0.98754525 -0.6649405 ]\n",
      " [ 0.6013668  -0.96962893]\n",
      " [-0.79144305  0.77557737]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.98754525 -0.6649405 ]\n",
      " [ 0.6013668  -0.96962893]\n",
      " [-0.79144305  0.77557737]\n",
      " [ 0.91446024 -0.13170937]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.6013668  -0.96962893]\n",
      " [-0.79144305  0.77557737]\n",
      " [ 0.91446024 -0.13170937]\n",
      " [-0.03438894 -0.8509414 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.79144305  0.77557737]\n",
      " [ 0.91446024 -0.13170937]\n",
      " [-0.03438894 -0.8509414 ]\n",
      " [-0.07328863  0.77948266]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.91446024 -0.13170937]\n",
      " [-0.03438894 -0.8509414 ]\n",
      " [-0.07328863  0.77948266]\n",
      " [ 0.29601666 -0.8722578 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.03438894 -0.8509414 ]\n",
      " [-0.07328863  0.77948266]\n",
      " [ 0.29601666 -0.8722578 ]\n",
      " [-0.85284406 -0.19337946]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.07328863  0.77948266]\n",
      " [ 0.29601666 -0.8722578 ]\n",
      " [-0.85284406 -0.19337946]\n",
      " [-0.9354873   0.7447594 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.29601666 -0.8722578 ]\n",
      " [-0.85284406 -0.19337946]\n",
      " [-0.9354873   0.7447594 ]\n",
      " [-0.78069293  0.6763273 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.85284406 -0.19337946]\n",
      " [-0.9354873   0.7447594 ]\n",
      " [-0.78069293  0.6763273 ]\n",
      " [-0.20016086 -0.61015934]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.9354873   0.7447594 ]\n",
      " [-0.78069293  0.6763273 ]\n",
      " [-0.20016086 -0.61015934]\n",
      " [-0.86550546  0.15447733]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.78069293  0.6763273 ]\n",
      " [-0.20016086 -0.61015934]\n",
      " [-0.86550546  0.15447733]\n",
      " [ 0.67256695 -0.7098177 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.20016086 -0.61015934]\n",
      " [-0.86550546  0.15447733]\n",
      " [ 0.67256695 -0.7098177 ]\n",
      " [ 0.5003226   0.4717274 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.86550546  0.15447733]\n",
      " [ 0.67256695 -0.7098177 ]\n",
      " [ 0.5003226   0.4717274 ]\n",
      " [ 0.9665421   0.7824824 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.67256695 -0.7098177 ]\n",
      " [ 0.5003226   0.4717274 ]\n",
      " [ 0.9665421   0.7824824 ]\n",
      " [-0.28257674  0.86382693]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.5003226   0.4717274 ]\n",
      " [ 0.9665421   0.7824824 ]\n",
      " [-0.28257674  0.86382693]\n",
      " [ 0.7606045   0.23788299]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.9665421   0.7824824 ]\n",
      " [-0.28257674  0.86382693]\n",
      " [ 0.7606045   0.23788299]\n",
      " [ 0.953034    0.9445978 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.28257674  0.86382693]\n",
      " [ 0.7606045   0.23788299]\n",
      " [ 0.953034    0.9445978 ]\n",
      " [-0.88928294 -0.74937814]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.7606045   0.23788299]\n",
      " [ 0.953034    0.9445978 ]\n",
      " [-0.88928294 -0.74937814]\n",
      " [-0.4639242  -0.98124313]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.953034    0.9445978 ]\n",
      " [-0.88928294 -0.74937814]\n",
      " [-0.4639242  -0.98124313]\n",
      " [ 0.6180451  -0.91421205]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.88928294 -0.74937814]\n",
      " [-0.4639242  -0.98124313]\n",
      " [ 0.6180451  -0.91421205]\n",
      " [ 0.13374491 -0.34932482]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.4639242  -0.98124313]\n",
      " [ 0.6180451  -0.91421205]\n",
      " [ 0.13374491 -0.34932482]\n",
      " [-0.53473395  0.3315229 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.6180451  -0.91421205]\n",
      " [ 0.13374491 -0.34932482]\n",
      " [-0.53473395  0.3315229 ]\n",
      " [ 0.70675856 -0.91791666]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.13374491 -0.34932482]\n",
      " [-0.53473395  0.3315229 ]\n",
      " [ 0.70675856 -0.91791666]\n",
      " [ 0.5994798  -0.12801193]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.53473395  0.3315229 ]\n",
      " [ 0.70675856 -0.91791666]\n",
      " [ 0.5994798  -0.12801193]\n",
      " [-0.4800132  -0.8124062 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.70675856 -0.91791666]\n",
      " [ 0.5994798  -0.12801193]\n",
      " [-0.4800132  -0.8124062 ]\n",
      " [ 0.854104   -0.8414279 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.5994798  -0.12801193]\n",
      " [-0.4800132  -0.8124062 ]\n",
      " [ 0.854104   -0.8414279 ]\n",
      " [ 0.9929792  -0.5109929 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.4800132  -0.8124062 ]\n",
      " [ 0.854104   -0.8414279 ]\n",
      " [ 0.9929792  -0.5109929 ]\n",
      " [ 0.2418031  -0.04108275]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.854104   -0.8414279 ]\n",
      " [ 0.9929792  -0.5109929 ]\n",
      " [ 0.2418031  -0.04108275]\n",
      " [-0.28696015  0.86450785]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.9929792  -0.5109929 ]\n",
      " [ 0.2418031  -0.04108275]\n",
      " [-0.28696015  0.86450785]\n",
      " [ 0.65883255  0.23607484]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.2418031  -0.04108275]\n",
      " [-0.28696015  0.86450785]\n",
      " [ 0.65883255  0.23607484]\n",
      " [ 0.97401047  0.95019317]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.28696015  0.86450785]\n",
      " [ 0.65883255  0.23607484]\n",
      " [ 0.97401047  0.95019317]\n",
      " [-0.9848276  -0.05328013]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.65883255  0.23607484]\n",
      " [ 0.97401047  0.95019317]\n",
      " [-0.9848276  -0.05328013]\n",
      " [-0.84403193 -0.07314585]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.97401047  0.95019317]\n",
      " [-0.9848276  -0.05328013]\n",
      " [-0.84403193 -0.07314585]\n",
      " [-0.46283248 -0.6417982 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.9848276  -0.05328013]\n",
      " [-0.84403193 -0.07314585]\n",
      " [-0.46283248 -0.6417982 ]\n",
      " [ 0.31109685 -0.95905143]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.84403193 -0.07314585]\n",
      " [-0.46283248 -0.6417982 ]\n",
      " [ 0.31109685 -0.95905143]\n",
      " [-0.51108384  0.7957703 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.46283248 -0.6417982 ]\n",
      " [ 0.31109685 -0.95905143]\n",
      " [-0.51108384  0.7957703 ]\n",
      " [-0.15696241  0.50344414]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.31109685 -0.95905143]\n",
      " [-0.51108384  0.7957703 ]\n",
      " [-0.15696241  0.50344414]\n",
      " [-0.35143918 -0.21294709]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.51108384  0.7957703 ]\n",
      " [-0.15696241  0.50344414]\n",
      " [-0.35143918 -0.21294709]\n",
      " [ 0.74871725  0.395854  ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.15696241  0.50344414]\n",
      " [-0.35143918 -0.21294709]\n",
      " [ 0.74871725  0.395854  ]\n",
      " [ 0.29537082 -0.2190491 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.35143918 -0.21294709]\n",
      " [ 0.74871725  0.395854  ]\n",
      " [ 0.29537082 -0.2190491 ]\n",
      " [-0.3251767   0.6237164 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.74871725  0.395854  ]\n",
      " [ 0.29537082 -0.2190491 ]\n",
      " [-0.3251767   0.6237164 ]\n",
      " [-0.01383207  0.2939459 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.29537082 -0.2190491 ]\n",
      " [-0.3251767   0.6237164 ]\n",
      " [-0.01383207  0.2939459 ]\n",
      " [-0.6866177   0.40354005]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.3251767   0.6237164 ]\n",
      " [-0.01383207  0.2939459 ]\n",
      " [-0.6866177   0.40354005]\n",
      " [ 0.31425202  0.3010531 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.01383207  0.2939459 ]\n",
      " [-0.6866177   0.40354005]\n",
      " [ 0.31425202  0.3010531 ]\n",
      " [ 0.7886657  -0.5063203 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.6866177   0.40354005]\n",
      " [ 0.31425202  0.3010531 ]\n",
      " [ 0.7886657  -0.5063203 ]\n",
      " [-0.6819612   0.92239773]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.31425202  0.3010531 ]\n",
      " [ 0.7886657  -0.5063203 ]\n",
      " [-0.6819612   0.92239773]\n",
      " [-0.90868586  0.82487154]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.7886657  -0.5063203 ]\n",
      " [-0.6819612   0.92239773]\n",
      " [-0.90868586  0.82487154]\n",
      " [-0.93515843 -0.745876  ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.6819612   0.92239773]\n",
      " [-0.90868586  0.82487154]\n",
      " [-0.93515843 -0.745876  ]\n",
      " [-0.29039907 -0.7945489 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.90868586  0.82487154]\n",
      " [-0.93515843 -0.745876  ]\n",
      " [-0.29039907 -0.7945489 ]\n",
      " [ 0.10762282  0.14139232]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.93515843 -0.745876  ]\n",
      " [-0.29039907 -0.7945489 ]\n",
      " [ 0.10762282  0.14139232]\n",
      " [ 0.4574623  -0.7083933 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.29039907 -0.7945489 ]\n",
      " [ 0.10762282  0.14139232]\n",
      " [ 0.4574623  -0.7083933 ]\n",
      " [ 0.21429114 -0.74874777]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.10762282  0.14139232]\n",
      " [ 0.4574623  -0.7083933 ]\n",
      " [ 0.21429114 -0.74874777]\n",
      " [ 0.8590606  -0.9666    ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.4574623  -0.7083933 ]\n",
      " [ 0.21429114 -0.74874777]\n",
      " [ 0.8590606  -0.9666    ]\n",
      " [-0.9377054   0.09693138]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.21429114 -0.74874777]\n",
      " [ 0.8590606  -0.9666    ]\n",
      " [-0.9377054   0.09693138]\n",
      " [-0.73835677 -0.9722164 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.8590606  -0.9666    ]\n",
      " [-0.9377054   0.09693138]\n",
      " [-0.73835677 -0.9722164 ]\n",
      " [ 0.56814265 -0.5259507 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.9377054   0.09693138]\n",
      " [-0.73835677 -0.9722164 ]\n",
      " [ 0.56814265 -0.5259507 ]\n",
      " [-0.5831074   0.7038737 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.73835677 -0.9722164 ]\n",
      " [ 0.56814265 -0.5259507 ]\n",
      " [-0.5831074   0.7038737 ]\n",
      " [ 0.16360076 -0.6593451 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.56814265 -0.5259507 ]\n",
      " [-0.5831074   0.7038737 ]\n",
      " [ 0.16360076 -0.6593451 ]\n",
      " [ 0.9166184  -0.9210108 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.5831074   0.7038737 ]\n",
      " [ 0.16360076 -0.6593451 ]\n",
      " [ 0.9166184  -0.9210108 ]\n",
      " [-0.9264472  -0.689525  ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.16360076 -0.6593451 ]\n",
      " [ 0.9166184  -0.9210108 ]\n",
      " [-0.9264472  -0.689525  ]\n",
      " [ 0.5101355   0.30700254]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.9166184  -0.9210108 ]\n",
      " [-0.9264472  -0.689525  ]\n",
      " [ 0.5101355   0.30700254]\n",
      " [ 0.97981495  0.62754375]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.9264472  -0.689525  ]\n",
      " [ 0.5101355   0.30700254]\n",
      " [ 0.97981495  0.62754375]\n",
      " [ 0.41086692 -0.3523414 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.5101355   0.30700254]\n",
      " [ 0.97981495  0.62754375]\n",
      " [ 0.41086692 -0.3523414 ]\n",
      " [ 0.24407166 -0.76258624]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.97981495  0.62754375]\n",
      " [ 0.41086692 -0.3523414 ]\n",
      " [ 0.24407166 -0.76258624]\n",
      " [-0.5393166   0.81425893]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.41086692 -0.3523414 ]\n",
      " [ 0.24407166 -0.76258624]\n",
      " [-0.5393166   0.81425893]\n",
      " [ 0.03064282 -0.04317106]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.24407166 -0.76258624]\n",
      " [-0.5393166   0.81425893]\n",
      " [ 0.03064282 -0.04317106]\n",
      " [ 0.44004738 -0.76681644]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.5393166   0.81425893]\n",
      " [ 0.03064282 -0.04317106]\n",
      " [ 0.44004738 -0.76681644]\n",
      " [-0.11756581  0.6971998 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.03064282 -0.04317106]\n",
      " [ 0.44004738 -0.76681644]\n",
      " [-0.11756581  0.6971998 ]\n",
      " [ 0.19731452 -0.69609565]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.44004738 -0.76681644]\n",
      " [-0.11756581  0.6971998 ]\n",
      " [ 0.19731452 -0.69609565]\n",
      " [ 0.4576396   0.7457897 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.11756581  0.6971998 ]\n",
      " [ 0.19731452 -0.69609565]\n",
      " [ 0.4576396   0.7457897 ]\n",
      " [-0.33922577  0.13016212]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.19731452 -0.69609565]\n",
      " [ 0.4576396   0.7457897 ]\n",
      " [-0.33922577  0.13016212]\n",
      " [ 0.7492142   0.25922385]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.4576396   0.7457897 ]\n",
      " [-0.33922577  0.13016212]\n",
      " [ 0.7492142   0.25922385]\n",
      " [ 0.7161353  -0.877058  ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.33922577  0.13016212]\n",
      " [ 0.7492142   0.25922385]\n",
      " [ 0.7161353  -0.877058  ]\n",
      " [ 0.94713044  0.7634623 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.7492142   0.25922385]\n",
      " [ 0.7161353  -0.877058  ]\n",
      " [ 0.94713044  0.7634623 ]\n",
      " [ 0.78253824 -0.27028856]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.7161353  -0.877058  ]\n",
      " [ 0.94713044  0.7634623 ]\n",
      " [ 0.78253824 -0.27028856]\n",
      " [ 0.7763096   0.29848048]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.94713044  0.7634623 ]\n",
      " [ 0.78253824 -0.27028856]\n",
      " [ 0.7763096   0.29848048]\n",
      " [ 0.8762591  -0.8953378 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.78253824 -0.27028856]\n",
      " [ 0.7763096   0.29848048]\n",
      " [ 0.8762591  -0.8953378 ]\n",
      " [ 0.9492515  -0.99890345]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.7763096   0.29848048]\n",
      " [ 0.8762591  -0.8953378 ]\n",
      " [ 0.9492515  -0.99890345]\n",
      " [ 0.11370797 -0.9594379 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.8762591  -0.8953378 ]\n",
      " [ 0.9492515  -0.99890345]\n",
      " [ 0.11370797 -0.9594379 ]\n",
      " [-0.26620814  0.34355256]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.9492515  -0.99890345]\n",
      " [ 0.11370797 -0.9594379 ]\n",
      " [-0.26620814  0.34355256]\n",
      " [ 0.86433375 -0.8498324 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.11370797 -0.9594379 ]\n",
      " [-0.26620814  0.34355256]\n",
      " [ 0.86433375 -0.8498324 ]\n",
      " [-0.23843645  0.34205535]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.26620814  0.34355256]\n",
      " [ 0.86433375 -0.8498324 ]\n",
      " [-0.23843645  0.34205535]\n",
      " [ 0.94307333 -0.81993026]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.86433375 -0.8498324 ]\n",
      " [-0.23843645  0.34205535]\n",
      " [ 0.94307333 -0.81993026]\n",
      " [-0.37693095 -0.6772394 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.23843645  0.34205535]\n",
      " [ 0.94307333 -0.81993026]\n",
      " [-0.37693095 -0.6772394 ]\n",
      " [ 0.999635   -0.9813713 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.94307333 -0.81993026]\n",
      " [-0.37693095 -0.6772394 ]\n",
      " [ 0.999635   -0.9813713 ]\n",
      " [-0.9596705  -0.9881053 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.37693095 -0.6772394 ]\n",
      " [ 0.999635   -0.9813713 ]\n",
      " [-0.9596705  -0.9881053 ]\n",
      " [-0.97334933  0.62579477]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.999635   -0.9813713 ]\n",
      " [-0.9596705  -0.9881053 ]\n",
      " [-0.97334933  0.62579477]\n",
      " [-0.9917088   0.9532537 ]], shape=(4, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[-0.9596705  -0.9881053 ]\n",
      " [-0.97334933  0.62579477]\n",
      " [-0.9917088   0.9532537 ]\n",
      " [-0.99461555  0.58265805]], shape=(4, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "window_size = 4\n",
    "for i in tf.range(window_size, tf.shape(actions)[0]):\n",
    "    print(actions[(i-window_size):i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
