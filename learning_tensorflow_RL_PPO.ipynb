{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import collections\n",
    "import numpy as np\n",
    "import statistics\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import layers\n",
    "from typing import Any, List, Sequence, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContinuousActor(tf.keras.Model):\n",
    "    \"\"\"Actor that outputs a policy directly\"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_actions: int,\n",
    "        num_hidden_units: int,\n",
    "        std_init = -2\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.means = layers.Dense(num_actions)\n",
    "        # self.stds = tf.Variable(tf.ones(num_actions))*std_init#lambda x: tf.zeros(num_actions)\n",
    "        # self.stds = layers.Dense(num_actions, activation='relu')\n",
    "        # tf.ones(num_actions) * 0.25\n",
    "    def call(self, inputs: tf.Tensor):\n",
    "        means = self.means(inputs)\n",
    "        # stds = self.stds(inputs)\n",
    "        # stds = tf.clip_by_value(stds, 1.0e-3, 1)\n",
    "        return means\n",
    "        # return tfp.distributions.MultivariateNormalDiag(loc = means, scale_diag = tf.exp(self.stds))\n",
    "\n",
    "\n",
    "class ActorCritic(tf.keras.Model):\n",
    "    \"\"\"combined actor-critic network. \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_actions: int,\n",
    "        num_hidden_units: int\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.common = layers.Dense(num_hidden_units, activation = 'relu')\n",
    "        # outputs scale, location params for mvn\n",
    "        self.actor = ContinuousActor(num_actions, num_hidden_units) #layers.Dense(num_actions)\n",
    "        self.critic = layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs: tf.Tensor):\n",
    "        x = self.common(inputs)\n",
    "        return self.actor(x), self.critic(x)\n",
    "\n",
    "class sepActorCritic(tf.keras.Model):\n",
    "    \"\"\"combined actor-critic network. \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_actions: int,\n",
    "        num_hidden_units: int\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.actor1 = layers.Dense(num_hidden_units, activation = 'relu')\n",
    "        # outputs scale, location params for mvn\n",
    "        self.actor2 = ContinuousActor(num_actions, num_hidden_units) \n",
    "        self.critic1 = layers.Dense(num_hidden_units, activation = 'relu')\n",
    "        self.critic2 = layers.Dense(1)\n",
    "\n",
    "    def call(self, inputs: tf.Tensor):\n",
    "        a = self.actor1(inputs)\n",
    "        c = self.critic1(inputs)\n",
    "        return self.actor2(a), self.critic2(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Actor(tf.keras.Model):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_actions,\n",
    "        num_hidden_units\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.fc1 = layers.Dense(num_hidden_units, activation = 'relu')\n",
    "        self.fc2 = layers.Dense(num_actions)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "class Critic(tf.keras.Model):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_hidden_units\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.fc1 = layers.Dense(num_hidden_units, activation = 'relu')\n",
    "        self.fc2 = layers.Dense(1)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "class FFNetwork(tf.keras.Model):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_hidden_units: int,\n",
    "        num_outputs: int\n",
    "        ):\n",
    "        super().__init__()\n",
    "        self.fc1 = layers.Dense(num_hidden_units, activation = 'relu')\n",
    "        self.fc2 = layers.Dense(num_outputs)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PPO:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        env_name: str,\n",
    "        gamma: float,\n",
    "        lam: float,\n",
    "        ent_coef: float,\n",
    "        vf_coef: float,\n",
    "        clip: float,\n",
    "        timesteps_per_batch: int,\n",
    "        max_timesteps_per_episode: int,\n",
    "        n_updates_per_iteration: int,\n",
    "        actor: tf.keras.Model,\n",
    "        optimizer_actor: tf.keras.optimizers.Optimizer,\n",
    "        critic: tf.keras.Model,\n",
    "        optimizer_critic: tf.keras.optimizers.Optimizer,\n",
    "        summary_writer\n",
    "        ):\n",
    "\n",
    "        # env\n",
    "        self.env_name = env_name\n",
    "        self.env = gym.make(self.env_name)\n",
    "        self.num_actions = self.env.action_space.shape[0]\n",
    "        \n",
    "        # learning params\n",
    "        self.gamma = gamma\n",
    "        self.lam = lam\n",
    "        self.ent_coef = ent_coef\n",
    "        self.vf_coef = vf_coef\n",
    "        self.clip = clip\n",
    "\n",
    "        # rollout params\n",
    "        self.timesteps_per_batch = timesteps_per_batch\n",
    "        self.max_timesteps_per_episode = max_timesteps_per_episode\n",
    "        self.n_updates_per_iteration = n_updates_per_iteration\n",
    "\n",
    "        # model \n",
    "        self.actor = actor\n",
    "        self.optimizer_actor = optimizer_actor\n",
    "        self.critic = critic\n",
    "        self.optimizer_critic = optimizer_critic\n",
    "\n",
    "        # other params\n",
    "        self.stds = tf.ones(self.num_actions) * 0.5 # TODO: make parameter\n",
    "        self.summary_writer = summary_writer\n",
    "        self.seed = 42 # TODO: make parameter\n",
    "\n",
    "    def learn(self, total_timesteps):\n",
    "        t_so_far = 0\n",
    "        while t_so_far < total_timesteps:\n",
    "            batch_states, batch_actions, batch_log_probs, batch_rewards, batch_lens, batch_dones, batch_values = self.rollout()\n",
    "\n",
    "            A_k = self.compute_gae(batch_rewards, batch_values, batch_dones)#batch_returns - V\n",
    "            V, _, _ = self.evaluate(batch_states, batch_actions)\n",
    "            batch_returns = A_k + V\n",
    "\n",
    "            # normalise advantages\n",
    "            A_k = (A_k - tf.reduce_mean(A_k)) / (tf.math.reduce_std(A_k) + 1.0e-10)\n",
    "\n",
    "            ## set up loss records\n",
    "            running_actor_loss = 0\n",
    "            running_critic_loss = 0\n",
    "            for _ in range(self.n_updates_per_iteration):\n",
    "                with tf.GradientTape(persistent=True) as tape:\n",
    "                    V, curr_log_probs, entropy = self.evaluate(batch_states, batch_actions)\n",
    "                    # this is the start of our computation graph?\n",
    "                    ratios = tf.exp(curr_log_probs - tf.squeeze(batch_log_probs))\n",
    "\n",
    "                    # calc surrogate losses\n",
    "                    surr1 = ratios * A_k\n",
    "                    surr2 = tf.clip_by_value(ratios, 1 - self.clip, 1 + self.clip) * A_k\n",
    "\n",
    "                    # get actor / critic losses \n",
    "                    entropy_loss = tf.reduce_mean(entropy)\n",
    "                    actor_loss = tf.reduce_mean(-tf.math.minimum(surr1, surr2)) - self.ent_coef * entropy_loss\n",
    "                    critic_loss = self.vf_coef * tf.reduce_mean((V - batch_returns)**2)\n",
    "\n",
    "                # backprop actor loss\n",
    "                actor_grads = tape.gradient(actor_loss, self.actor.trainable_variables)\n",
    "                self.optimizer_actor.apply_gradients(zip(actor_grads, self.actor.trainable_variables))\n",
    "\n",
    "                # backprop critic loss\n",
    "                critic_grads = tape.gradient(critic_loss, self.critic.trainable_variables)\n",
    "                self.optimizer_critic.apply_gradients(zip(critic_grads, self.critic.trainable_variables))\n",
    "                \n",
    "                # for logging\n",
    "                running_actor_loss += tf.stop_gradient(actor_loss)\n",
    "                running_critic_loss += tf.stop_gradient(critic_loss)            \n",
    "            \n",
    "            t_so_far += np.sum(batch_lens)\n",
    "            with self.summary_writer.as_default():\n",
    "                tf.summary.scalar('actor_loss', running_actor_loss / self.n_updates_per_iteration, step = t_so_far)\n",
    "                tf.summary.scalar('critic_loss', running_critic_loss / self.n_updates_per_iteration, step = t_so_far)\n",
    "                tf.summary.scalar('returns', tf.reduce_mean(batch_returns), step = t_so_far)\n",
    "                tf.summary.scalar('rewards', tf.reduce_mean([np.sum(i) for i in batch_rewards]), step = t_so_far)\n",
    "\n",
    "\n",
    "    def rollout(self):\n",
    "        \"\"\"\n",
    "        Runs a single episode in the environment and accumulates data\n",
    "        \"\"\"\n",
    "\n",
    "        # store results\n",
    "        batch_states = []\n",
    "        batch_actions = []\n",
    "        batch_log_probs = []\n",
    "        batch_rewards = []\n",
    "        batch_returns = []\n",
    "        batch_lens = []\n",
    "        batch_values = []\n",
    "        batch_dones = []\n",
    "\n",
    "        # num timesteps so far\n",
    "        t = 0\n",
    "\n",
    "        while t < self.timesteps_per_batch:\n",
    "            ep_rewards = []\n",
    "            ep_values = []\n",
    "            ep_dones = []\n",
    "\n",
    "            state, _ = self.env.reset()\n",
    "            done = False\n",
    "\n",
    "            for ep_t in range(self.max_timesteps_per_episode):\n",
    "\n",
    "                # increment timesteps\n",
    "                t += 1\n",
    "\n",
    "                # collect observations\n",
    "                batch_states.append(state)\n",
    "                \n",
    "                action, log_prob = self.get_action(state)\n",
    "                value = self.critic(tf.expand_dims(state, 0))\n",
    "                state, reward, truncated, terminated, _ = self.env.step(action)\n",
    "                done = truncated or terminated\n",
    "\n",
    "                # collect reward, action and log prob\n",
    "                ep_rewards.append(reward)\n",
    "                ep_values.append(tf.reshape(value, [-1]))\n",
    "                ep_dones.append(done)\n",
    "\n",
    "                batch_actions.append(action)\n",
    "                batch_log_probs.append(log_prob)\n",
    "                \n",
    "\n",
    "                if done:\n",
    "                    break\n",
    "            \n",
    "            # collect episode length and rewards\n",
    "            batch_lens.append(ep_t + 1)\n",
    "            batch_rewards.append(ep_rewards)\n",
    "            batch_values.append(ep_values)\n",
    "            batch_dones.append(ep_dones)\n",
    "\n",
    "        # convert to tensors\n",
    "        batch_states = tf.convert_to_tensor(batch_states, dtype = tf.float32)\n",
    "        batch_actions = tf.convert_to_tensor(batch_actions, dtype = tf.float32)\n",
    "        batch_log_probs = tf.convert_to_tensor(batch_log_probs, dtype = tf.float32)\n",
    "\n",
    "        # batch_returns = self.compute_returns(batch_rewards)\n",
    "\n",
    "        return batch_states, batch_actions, batch_log_probs, batch_rewards, batch_lens, batch_dones, batch_values\n",
    "\n",
    "\n",
    "    def get_action(self, state):\n",
    "\n",
    "        means = self.actor(tf.expand_dims(state, 0))\n",
    "        policy = tfp.distributions.MultivariateNormalDiag(loc = means, scale_diag = self.stds)\n",
    "\n",
    "        # TODO: squash / scale action (do I need to?)\n",
    "        action = policy.sample()[0]\n",
    "        log_prob = policy.log_prob(action)\n",
    "\n",
    "        return action, log_prob\n",
    "\n",
    "    def compute_returns(self, rewards):\n",
    "        batch_returns = []\n",
    "        for ep_rewards in reversed((rewards)):\n",
    "\n",
    "            discounted_reward = 0 # reward so far\n",
    "\n",
    "            for reward in reversed(ep_rewards):\n",
    "                discounted_reward = reward + self.gamma * discounted_reward\n",
    "                batch_returns.insert(0, discounted_reward)\n",
    "            \n",
    "        # convert to tensor\n",
    "        batch_returns = tf.convert_to_tensor(batch_returns, dtype = tf.float32)\n",
    "\n",
    "        return batch_returns\n",
    "\n",
    "\n",
    "    def compute_gae(self, rewards, values, dones):\n",
    "        batch_advantages = []\n",
    "\n",
    "        for ep_rewards, ep_values, ep_dones in zip(rewards, values, dones):\n",
    "            advantages = []\n",
    "            last_advantage = 0\n",
    "\n",
    "            for t in reversed(range(len(ep_rewards))):\n",
    "                if t + 1 < len(ep_rewards):\n",
    "                    delta = ep_rewards[t] + self.gamma * ep_values[t+1] * (1 - ep_dones[t+1]) - ep_values[t]\n",
    "                else:\n",
    "                    delta = ep_rewards[t] - ep_values[t]\n",
    "\n",
    "                advantage = delta + self.gamma * self.lam * (1 - ep_dones[t]) * last_advantage\n",
    "                last_advantage = advantage\n",
    "                advantages.insert(0, advantage)\n",
    "\n",
    "            batch_advantages.extend(advantages)\n",
    "        \n",
    "        return tf.squeeze(tf.convert_to_tensor(batch_advantages, dtype = tf.float32))\n",
    "    \n",
    "    def evaluate(self, batch_states, batch_actions):\n",
    "        V = tf.squeeze(self.critic(batch_states))\n",
    "        mean = self.actor(batch_states)\n",
    "        policy = tfp.distributions.MultivariateNormalDiag(mean, self.stds)\n",
    "\n",
    "        log_probs = policy.log_prob(batch_actions)\n",
    "\n",
    "        return V, log_probs, policy.entropy()\n",
    "\n",
    "    def test(self, num_episodes):\n",
    "        env = gym.make(self.env_name, render_mode = 'human')\n",
    "        for i in range(num_episodes):\n",
    "            state, _ = env.reset(seed = seed)\n",
    "            done = False\n",
    "            step = 0\n",
    "            while not done:\n",
    "                action, _ = self.get_action(state)\n",
    "                next_state, reward, terminated, truncated, info = env.step(action)\n",
    "                done = terminated or truncated\n",
    "                state = next_state\n",
    "\n",
    "                step += 1\n",
    "        env.close()\n",
    "\n",
    "def get_next_run(log_dir):\n",
    "    next_run = max([0]+[int(j) for j in [i.split('_')[-1] for i in os.listdir(log_dir)] if j.isdigit()]) + 1\n",
    "    return log_dir + f'/run_{next_run}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving logs to:  ./logs/run_207\n"
     ]
    }
   ],
   "source": [
    "ENV = 'LunarLanderContinuous-v2'#'Pendulum-v1'#\n",
    "\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "# env = gym.make(ENV)\n",
    "eps = np.finfo(np.float32).eps.item()\n",
    "\n",
    "optimizer_actor = tf.keras.optimizers.RMSprop(learning_rate=0.0007, clipnorm=0.5)\n",
    "optimizer_critic = tf.keras.optimizers.RMSprop(learning_rate=0.0007, clipnorm=0.5)\n",
    "num_actions = env.action_space.shape[0]\n",
    "num_hidden_units = 64\n",
    "\n",
    "actor = Actor(num_actions, num_hidden_units)\n",
    "critic = Critic(num_hidden_units)\n",
    "\n",
    "\n",
    "log_dir = get_next_run('./logs') \n",
    "print('Saving logs to: ', log_dir)\n",
    "summary_writer = tf.summary.create_file_writer(logdir = log_dir)\n",
    "\n",
    "\n",
    "agent = PPO(        \n",
    "    env_name = ENV,\n",
    "    gamma = 0.999,\n",
    "    lam = 0.98,\n",
    "    ent_coef = 0.01,\n",
    "    vf_coef = 0.4,\n",
    "    clip = 0.2,\n",
    "    timesteps_per_batch = 800,\n",
    "    max_timesteps_per_episode = 200,\n",
    "    n_updates_per_iteration = 4,\n",
    "    actor = actor,\n",
    "    optimizer_actor = optimizer_actor,\n",
    "    critic = critic,\n",
    "    optimizer_critic = optimizer_critic,\n",
    "    summary_writer= summary_writer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.learn(240000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.test(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMPPO:\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        env_name: str,\n",
    "        gamma: float,\n",
    "        lam: float,\n",
    "        ent_coef: float,\n",
    "        vf_coef: float,\n",
    "        clip: float,\n",
    "        window_size: int,\n",
    "        timesteps_per_batch: int,\n",
    "        max_timesteps_per_episode: int,\n",
    "        n_updates_per_iteration: int,\n",
    "        actor: tf.keras.Model,\n",
    "        optimizer_actor: tf.keras.optimizers.Optimizer,\n",
    "        critic: tf.keras.Model,\n",
    "        optimizer_critic: tf.keras.optimizers.Optimizer,\n",
    "        summary_writer\n",
    "        ):\n",
    "\n",
    "        # env\n",
    "        self.env_name = env_name\n",
    "        self.env = gym.make(self.env_name)\n",
    "        self.num_actions = self.env.action_space.shape[0]\n",
    "        \n",
    "        # learning params\n",
    "        self.gamma = gamma\n",
    "        self.lam = lam\n",
    "        self.ent_coef = ent_coef\n",
    "        self.vf_coef = vf_coef\n",
    "        self.clip = clip\n",
    "        self.window_size = window_size\n",
    "\n",
    "        # rollout params\n",
    "        self.timesteps_per_batch = timesteps_per_batch\n",
    "        self.max_timesteps_per_episode = max_timesteps_per_episode\n",
    "        self.n_updates_per_iteration = n_updates_per_iteration\n",
    "\n",
    "        # model \n",
    "        self.actor = actor\n",
    "        self.optimizer_actor = optimizer_actor\n",
    "        self.critic = critic\n",
    "        self.optimizer_critic = optimizer_critic\n",
    "\n",
    "        # other params\n",
    "        self.stds = tf.ones(self.num_actions) * 0.5\n",
    "        self.summary_writer = summary_writer\n",
    "\n",
    "    def learn(self, total_timesteps):\n",
    "        t_so_far = 0\n",
    "        while t_so_far < total_timesteps:\n",
    "            batch_states, batch_actions, batch_log_probs, batch_rewards, batch_lens, batch_dones, batch_values = self.rollout()\n",
    "\n",
    "            A_k = self.compute_gae(batch_rewards, batch_values, batch_dones)#batch_returns - V\n",
    "            V, _, _ = self.evaluate(batch_states, batch_actions)\n",
    "            batch_returns = A_k + V\n",
    "\n",
    "            # normalise advantages\n",
    "            A_k = (A_k - tf.reduce_mean(A_k)) / (tf.math.reduce_std(A_k) + 1.0e-10)\n",
    "\n",
    "            ## set up loss records\n",
    "            running_actor_loss = 0\n",
    "            running_critic_loss = 0\n",
    "            for _ in range(self.n_updates_per_iteration):\n",
    "                with tf.GradientTape(persistent=True) as tape:\n",
    "                    V, curr_log_probs, entropy = self.evaluate(batch_states, batch_actions)\n",
    "                    \n",
    "                    ratios = tf.exp(curr_log_probs - tf.squeeze(batch_log_probs))\n",
    "\n",
    "                    # calc surrogate losses\n",
    "                    surr1 = ratios * A_k\n",
    "                    surr2 = tf.clip_by_value(ratios, 1 - self.clip, 1 + self.clip) * A_k\n",
    "\n",
    "                    # get actor / critic losses \n",
    "                    entropy_loss = tf.reduce_mean(entropy)\n",
    "                    actor_loss = tf.reduce_mean(-tf.math.minimum(surr1, surr2)) - self.ent_coef * entropy_loss\n",
    "                    critic_loss = self.vf_coef * tf.reduce_mean((V - batch_returns)**2)\n",
    "\n",
    "                # backprop actor loss\n",
    "                actor_grads = tape.gradient(actor_loss, self.actor.trainable_variables)\n",
    "                self.optimizer_actor.apply_gradients(zip(actor_grads, self.actor.trainable_variables))\n",
    "\n",
    "                # backprop critic loss\n",
    "                critic_grads = tape.gradient(critic_loss, self.critic.trainable_variables)\n",
    "                self.optimizer_critic.apply_gradients(zip(critic_grads, self.critic.trainable_variables))\n",
    "                \n",
    "                # for logging\n",
    "                running_actor_loss += tf.stop_gradient(actor_loss)\n",
    "                running_critic_loss += tf.stop_gradient(critic_loss)            \n",
    "            \n",
    "            t_so_far += np.sum(batch_lens)\n",
    "            with self.summary_writer.as_default():\n",
    "                tf.summary.scalar('actor_loss', running_actor_loss / self.n_updates_per_iteration, step = t_so_far)\n",
    "                tf.summary.scalar('critic_loss', running_critic_loss / self.n_updates_per_iteration, step = t_so_far)\n",
    "                tf.summary.scalar('returns', tf.reduce_mean(batch_returns), step = t_so_far)\n",
    "                tf.summary.scalar('rewards', tf.reduce_mean([np.sum(i) for i in batch_rewards]), step = t_so_far)\n",
    "\n",
    "\n",
    "    def rollout(self):\n",
    "        \"\"\"\n",
    "        Runs a single episode in the environment and accumulates data\n",
    "        \"\"\"\n",
    "\n",
    "        # store results\n",
    "        batch_states = []\n",
    "        batch_actions = []\n",
    "        batch_log_probs = []\n",
    "        batch_rewards = []\n",
    "        batch_returns = []\n",
    "        batch_lens = []\n",
    "        batch_values = []\n",
    "        batch_dones = []\n",
    "\n",
    "        # num timesteps so far\n",
    "        t = 0\n",
    "\n",
    "        while t < self.timesteps_per_batch:\n",
    "            ep_rewards = []\n",
    "            ep_values = []\n",
    "            ep_dones = []\n",
    "\n",
    "            state, _ = self.env.reset()\n",
    "            done = False\n",
    "\n",
    "            for ep_t in range(self.max_timesteps_per_episode):\n",
    "\n",
    "                # increment timesteps\n",
    "                t += 1\n",
    "\n",
    "                # collect observations\n",
    "                batch_states.append(state)\n",
    "                \n",
    "                # pad states for use in lstm\n",
    "                padded = self.pad_input(batch_states, ep_t + 1)\n",
    "                action, log_prob = self.get_action(padded)\n",
    "                value = self.critic(tf.expand_dims(padded, 0)) # may need to adjust dims?\n",
    "                state, reward, truncated, terminated, _ = self.env.step(action)\n",
    "                done = truncated or terminated\n",
    "\n",
    "                # collect reward, action and log prob\n",
    "                ep_rewards.append(reward)\n",
    "                ep_values.append(tf.reshape(value, [-1]))\n",
    "                ep_dones.append(done)\n",
    "\n",
    "                batch_actions.append(action)\n",
    "                batch_log_probs.append(log_prob)\n",
    "                \n",
    "\n",
    "                if done:\n",
    "                    break\n",
    "            \n",
    "            # collect episode length and rewards\n",
    "            batch_lens.append(ep_t + 1)\n",
    "            batch_rewards.append(ep_rewards)\n",
    "            batch_values.append(ep_values)\n",
    "            batch_dones.append(ep_dones)\n",
    "\n",
    "        # convert to tensors\n",
    "        batch_states = tf.convert_to_tensor(batch_states, dtype = tf.float32)\n",
    "        batch_actions = tf.convert_to_tensor(batch_actions, dtype = tf.float32)\n",
    "        batch_log_probs = tf.convert_to_tensor(batch_log_probs, dtype = tf.float32)\n",
    "\n",
    "        # batch_returns = self.compute_returns(batch_rewards)\n",
    "\n",
    "        return batch_states, batch_actions, batch_log_probs, batch_rewards, batch_lens, batch_dones, batch_values\n",
    "        \n",
    "    def pad_input(self, batch_states, num):\n",
    "        ### TODO: DEBUG - why does this come up with an empty batch_state?\n",
    "        print(num)\n",
    "        print(batch_states)\n",
    "        # get the last 'window_size' states\n",
    "        to_pad = batch_states[(num - self.window_size):num]\n",
    "        print(tf.shape(to_pad))\n",
    "        print(to_pad)\n",
    "\n",
    "        # get size of padding - 0 if we have enough\n",
    "        pad_size = np.max([0, window_size-tf.shape(to_pad)[0]], axis = 0)\n",
    "        \n",
    "        # get the padded vals\n",
    "        padded = tf.pad(to_pad, [[0,pad_size],[0,0]])\n",
    "\n",
    "        return padded\n",
    "\n",
    "    def get_action(self, state):\n",
    "\n",
    "        means = self.actor(tf.expand_dims(state, 0))\n",
    "        policy = tfp.distributions.MultivariateNormalDiag(loc = means, scale_diag = self.stds)\n",
    "\n",
    "        # TODO: squash / scale action (do I need to?)\n",
    "        action = policy.sample()[0]\n",
    "        log_prob = policy.log_prob(action)\n",
    "\n",
    "        return action, log_prob\n",
    "\n",
    "    def compute_returns(self, rewards):\n",
    "        batch_returns = []\n",
    "        for ep_rewards in reversed((rewards)):\n",
    "\n",
    "            discounted_reward = 0 # reward so far\n",
    "\n",
    "            for reward in reversed(ep_rewards):\n",
    "                discounted_reward = reward + self.gamma * discounted_reward\n",
    "                batch_returns.insert(0, discounted_reward)\n",
    "            \n",
    "        # convert to tensor\n",
    "        batch_returns = tf.convert_to_tensor(batch_returns, dtype = tf.float32)\n",
    "\n",
    "        return batch_returns\n",
    "\n",
    "\n",
    "    def compute_gae(self, rewards, values, dones):\n",
    "        batch_advantages = []\n",
    "\n",
    "        for ep_rewards, ep_values, ep_dones in zip(rewards, values, dones):\n",
    "            advantages = []\n",
    "            last_advantage = 0\n",
    "\n",
    "            for t in reversed(range(len(ep_rewards))):\n",
    "                if t + 1 < len(ep_rewards):\n",
    "                    delta = ep_rewards[t] + self.gamma * ep_values[t+1] * (1 - ep_dones[t+1]) - ep_values[t]\n",
    "                else:\n",
    "                    delta = ep_rewards[t] - ep_values[t]\n",
    "\n",
    "                advantage = delta + self.gamma * self.lam * (1 - ep_dones[t]) * last_advantage\n",
    "                last_advantage = advantage\n",
    "                advantages.insert(0, advantage)\n",
    "\n",
    "            batch_advantages.extend(advantages)\n",
    "        \n",
    "        return tf.squeeze(tf.convert_to_tensor(batch_advantages, dtype = tf.float32))\n",
    "\n",
    "    def prepare_batch_for_lstm(self, batch_states):\n",
    "        \"\"\"wraps states into lstm sequence format\"\"\"\n",
    "\n",
    "        initial_padded_states = tf.convert_to_tensor(\n",
    "            [tf.pad(states[:(i+1)][::-1], [[0,np.max([0, self.window_size-(i+1)], axis = 0)],[0,0]]) for i in tf.range(0, self.window_size)]\n",
    "            )\n",
    "        remaining_states = tf.convert_to_tensor(\n",
    "            [states[(i-self.window_size):i] for i in tf.range(self.window_size, tf.shape(states)[0])]\n",
    "            )\n",
    "        combined_states = tf.concat(\n",
    "            [initial_padded_states, remaining_states],\n",
    "            axis = 0)\n",
    "\n",
    "        return combined_states\n",
    "    \n",
    "    def evaluate(self, batch_states, batch_actions):\n",
    "\n",
    "        lstm_batch_states = self.prepare_batch_for_lstm(batch_states)\n",
    "        V = tf.squeeze(self.critic(lstm_batch_states))\n",
    "        mean = self.actor(lstm_batch_states)\n",
    "        policy = tfp.distributions.MultivariateNormalDiag(mean, self.stds)\n",
    "\n",
    "        log_probs = policy.log_prob(batch_actions)\n",
    "\n",
    "        return V, log_probs, policy.entropy()\n",
    "\n",
    "    def test(self, num_episodes):\n",
    "        env = gym.make(self.env_name, render_mode = 'human')\n",
    "        for i in range(num_episodes):\n",
    "            state, _ = env.reset(seed = seed)\n",
    "            done = False\n",
    "            step = 0\n",
    "            while not done:\n",
    "                action, _ = self.get_action(state)\n",
    "                next_state, reward, terminated, truncated, info = env.step(action)\n",
    "                done = terminated or truncated\n",
    "                state = next_state\n",
    "\n",
    "                step += 1\n",
    "        env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMNet(tf.keras.Model):\n",
    "\n",
    "    def __init__(self, num_hidden_units, num_outputs):\n",
    "        super().__init__()\n",
    "        self.lstm = layers.LSTM(num_hidden_units)\n",
    "        self.fc = layers.Dense(num_outputs)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.lstm(x)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving logs to:  ./logs/run_206\n"
     ]
    }
   ],
   "source": [
    "ENV = 'LunarLanderContinuous-v2'#'Pendulum-v1'#\n",
    "\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "env = gym.make(ENV)\n",
    "eps = np.finfo(np.float32).eps.item()\n",
    "\n",
    "optimizer_actor = tf.keras.optimizers.RMSprop(learning_rate=0.0007, clipnorm=0.5)\n",
    "optimizer_critic = tf.keras.optimizers.RMSprop(learning_rate=0.0007, clipnorm=0.5)\n",
    "num_actions = env.action_space.shape[0]\n",
    "num_hidden_units = 64\n",
    "\n",
    "actor = LSTMNet(num_hidden_units, num_actions)#Actor(num_actions, num_hidden_units)\n",
    "critic = LSTMNet(num_hidden_units, 1)\n",
    "\n",
    "log_dir = get_next_run('./logs') \n",
    "print('Saving logs to: ', log_dir)\n",
    "summary_writer = tf.summary.create_file_writer(logdir = log_dir)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[array([ 0.00163717,  1.4129504 ,  0.165805  ,  0.09023532, -0.0018902 ,\n",
      "       -0.03755725,  0.        ,  0.        ], dtype=float32)]\n",
      "tf.Tensor([1 8], shape=(2,), dtype=int32)\n",
      "[array([ 0.00163717,  1.4129504 ,  0.165805  ,  0.09023532, -0.0018902 ,\n",
      "       -0.03755725,  0.        ,  0.        ], dtype=float32)]\n",
      "2\n",
      "[array([ 0.00163717,  1.4129504 ,  0.165805  ,  0.09023532, -0.0018902 ,\n",
      "       -0.03755725,  0.        ,  0.        ], dtype=float32), array([ 0.0033493 ,  1.4144068 ,  0.17500368,  0.06472376, -0.00563567,\n",
      "       -0.07491585,  0.        ,  0.        ], dtype=float32)]\n",
      "tf.Tensor([2 8], shape=(2,), dtype=int32)\n",
      "[array([ 0.00163717,  1.4129504 ,  0.165805  ,  0.09023532, -0.0018902 ,\n",
      "       -0.03755725,  0.        ,  0.        ], dtype=float32), array([ 0.0033493 ,  1.4144068 ,  0.17500368,  0.06472376, -0.00563567,\n",
      "       -0.07491585,  0.        ,  0.        ], dtype=float32)]\n",
      "3\n",
      "[array([ 0.00163717,  1.4129504 ,  0.165805  ,  0.09023532, -0.0018902 ,\n",
      "       -0.03755725,  0.        ,  0.        ], dtype=float32), array([ 0.0033493 ,  1.4144068 ,  0.17500368,  0.06472376, -0.00563567,\n",
      "       -0.07491585,  0.        ,  0.        ], dtype=float32), array([ 0.00496588,  1.4160489 ,  0.16591594,  0.07295343, -0.00985315,\n",
      "       -0.08435733,  0.        ,  0.        ], dtype=float32)]\n",
      "tf.Tensor([1 8], shape=(2,), dtype=int32)\n",
      "[array([ 0.00496588,  1.4160489 ,  0.16591594,  0.07295343, -0.00985315,\n",
      "       -0.08435733,  0.        ,  0.        ], dtype=float32)]\n",
      "4\n",
      "[array([ 0.00163717,  1.4129504 ,  0.165805  ,  0.09023532, -0.0018902 ,\n",
      "       -0.03755725,  0.        ,  0.        ], dtype=float32), array([ 0.0033493 ,  1.4144068 ,  0.17500368,  0.06472376, -0.00563567,\n",
      "       -0.07491585,  0.        ,  0.        ], dtype=float32), array([ 0.00496588,  1.4160489 ,  0.16591594,  0.07295343, -0.00985315,\n",
      "       -0.08435733,  0.        ,  0.        ], dtype=float32), array([ 0.00662374,  1.4170928 ,  0.17109025,  0.04635807, -0.01510478,\n",
      "       -0.10504226,  0.        ,  0.        ], dtype=float32)]\n",
      "tf.Tensor([4 8], shape=(2,), dtype=int32)\n",
      "[array([ 0.00163717,  1.4129504 ,  0.165805  ,  0.09023532, -0.0018902 ,\n",
      "       -0.03755725,  0.        ,  0.        ], dtype=float32), array([ 0.0033493 ,  1.4144068 ,  0.17500368,  0.06472376, -0.00563567,\n",
      "       -0.07491585,  0.        ,  0.        ], dtype=float32), array([ 0.00496588,  1.4160489 ,  0.16591594,  0.07295343, -0.00985315,\n",
      "       -0.08435733,  0.        ,  0.        ], dtype=float32), array([ 0.00662374,  1.4170928 ,  0.17109025,  0.04635807, -0.01510478,\n",
      "       -0.10504226,  0.        ,  0.        ], dtype=float32)]\n",
      "5\n",
      "[array([ 0.00163717,  1.4129504 ,  0.165805  ,  0.09023532, -0.0018902 ,\n",
      "       -0.03755725,  0.        ,  0.        ], dtype=float32), array([ 0.0033493 ,  1.4144068 ,  0.17500368,  0.06472376, -0.00563567,\n",
      "       -0.07491585,  0.        ,  0.        ], dtype=float32), array([ 0.00496588,  1.4160489 ,  0.16591594,  0.07295343, -0.00985315,\n",
      "       -0.08435733,  0.        ,  0.        ], dtype=float32), array([ 0.00662374,  1.4170928 ,  0.17109025,  0.04635807, -0.01510478,\n",
      "       -0.10504226,  0.        ,  0.        ], dtype=float32), array([ 0.00818119,  1.4181907 ,  0.16158228,  0.04872749, -0.02086745,\n",
      "       -0.11526398,  0.        ,  0.        ], dtype=float32)]\n",
      "tf.Tensor([4 8], shape=(2,), dtype=int32)\n",
      "[array([ 0.0033493 ,  1.4144068 ,  0.17500368,  0.06472376, -0.00563567,\n",
      "       -0.07491585,  0.        ,  0.        ], dtype=float32), array([ 0.00496588,  1.4160489 ,  0.16591594,  0.07295343, -0.00985315,\n",
      "       -0.08435733,  0.        ,  0.        ], dtype=float32), array([ 0.00662374,  1.4170928 ,  0.17109025,  0.04635807, -0.01510478,\n",
      "       -0.10504226,  0.        ,  0.        ], dtype=float32), array([ 0.00818119,  1.4181907 ,  0.16158228,  0.04872749, -0.02086745,\n",
      "       -0.11526398,  0.        ,  0.        ], dtype=float32)]\n",
      "6\n",
      "[array([ 0.00163717,  1.4129504 ,  0.165805  ,  0.09023532, -0.0018902 ,\n",
      "       -0.03755725,  0.        ,  0.        ], dtype=float32), array([ 0.0033493 ,  1.4144068 ,  0.17500368,  0.06472376, -0.00563567,\n",
      "       -0.07491585,  0.        ,  0.        ], dtype=float32), array([ 0.00496588,  1.4160489 ,  0.16591594,  0.07295343, -0.00985315,\n",
      "       -0.08435733,  0.        ,  0.        ], dtype=float32), array([ 0.00662374,  1.4170928 ,  0.17109025,  0.04635807, -0.01510478,\n",
      "       -0.10504226,  0.        ,  0.        ], dtype=float32), array([ 0.00818119,  1.4181907 ,  0.16158228,  0.04872749, -0.02086745,\n",
      "       -0.11526398,  0.        ,  0.        ], dtype=float32), array([ 0.00981636,  1.4195073 ,  0.17081414,  0.0583933 , -0.02808201,\n",
      "       -0.14430468,  0.        ,  0.        ], dtype=float32)]\n",
      "tf.Tensor([4 8], shape=(2,), dtype=int32)\n",
      "[array([ 0.00496588,  1.4160489 ,  0.16591594,  0.07295343, -0.00985315,\n",
      "       -0.08435733,  0.        ,  0.        ], dtype=float32), array([ 0.00662374,  1.4170928 ,  0.17109025,  0.04635807, -0.01510478,\n",
      "       -0.10504226,  0.        ,  0.        ], dtype=float32), array([ 0.00818119,  1.4181907 ,  0.16158228,  0.04872749, -0.02086745,\n",
      "       -0.11526398,  0.        ,  0.        ], dtype=float32), array([ 0.00981636,  1.4195073 ,  0.17081414,  0.0583933 , -0.02808201,\n",
      "       -0.14430468,  0.        ,  0.        ], dtype=float32)]\n",
      "7\n",
      "[array([ 0.00163717,  1.4129504 ,  0.165805  ,  0.09023532, -0.0018902 ,\n",
      "       -0.03755725,  0.        ,  0.        ], dtype=float32), array([ 0.0033493 ,  1.4144068 ,  0.17500368,  0.06472376, -0.00563567,\n",
      "       -0.07491585,  0.        ,  0.        ], dtype=float32), array([ 0.00496588,  1.4160489 ,  0.16591594,  0.07295343, -0.00985315,\n",
      "       -0.08435733,  0.        ,  0.        ], dtype=float32), array([ 0.00662374,  1.4170928 ,  0.17109025,  0.04635807, -0.01510478,\n",
      "       -0.10504226,  0.        ,  0.        ], dtype=float32), array([ 0.00818119,  1.4181907 ,  0.16158228,  0.04872749, -0.02086745,\n",
      "       -0.11526398,  0.        ,  0.        ], dtype=float32), array([ 0.00981636,  1.4195073 ,  0.17081414,  0.0583933 , -0.02808201,\n",
      "       -0.14430468,  0.        ,  0.        ], dtype=float32), array([ 0.01145172,  1.4202244 ,  0.17083533,  0.03171718, -0.03529498,\n",
      "       -0.14427301,  0.        ,  0.        ], dtype=float32)]\n",
      "tf.Tensor([4 8], shape=(2,), dtype=int32)\n",
      "[array([ 0.00662374,  1.4170928 ,  0.17109025,  0.04635807, -0.01510478,\n",
      "       -0.10504226,  0.        ,  0.        ], dtype=float32), array([ 0.00818119,  1.4181907 ,  0.16158228,  0.04872749, -0.02086745,\n",
      "       -0.11526398,  0.        ,  0.        ], dtype=float32), array([ 0.00981636,  1.4195073 ,  0.17081414,  0.0583933 , -0.02808201,\n",
      "       -0.14430468,  0.        ,  0.        ], dtype=float32), array([ 0.01145172,  1.4202244 ,  0.17083533,  0.03171718, -0.03529498,\n",
      "       -0.14427301,  0.        ,  0.        ], dtype=float32)]\n",
      "8\n",
      "[array([ 0.00163717,  1.4129504 ,  0.165805  ,  0.09023532, -0.0018902 ,\n",
      "       -0.03755725,  0.        ,  0.        ], dtype=float32), array([ 0.0033493 ,  1.4144068 ,  0.17500368,  0.06472376, -0.00563567,\n",
      "       -0.07491585,  0.        ,  0.        ], dtype=float32), array([ 0.00496588,  1.4160489 ,  0.16591594,  0.07295343, -0.00985315,\n",
      "       -0.08435733,  0.        ,  0.        ], dtype=float32), array([ 0.00662374,  1.4170928 ,  0.17109025,  0.04635807, -0.01510478,\n",
      "       -0.10504226,  0.        ,  0.        ], dtype=float32), array([ 0.00818119,  1.4181907 ,  0.16158228,  0.04872749, -0.02086745,\n",
      "       -0.11526398,  0.        ,  0.        ], dtype=float32), array([ 0.00981636,  1.4195073 ,  0.17081414,  0.0583933 , -0.02808201,\n",
      "       -0.14430468,  0.        ,  0.        ], dtype=float32), array([ 0.01145172,  1.4202244 ,  0.17083533,  0.03171718, -0.03529498,\n",
      "       -0.14427301,  0.        ,  0.        ], dtype=float32), array([ 0.01308746,  1.4203422 ,  0.17085637,  0.00504831, -0.04250716,\n",
      "       -0.14425674,  0.        ,  0.        ], dtype=float32)]\n",
      "tf.Tensor([4 8], shape=(2,), dtype=int32)\n",
      "[array([ 0.00818119,  1.4181907 ,  0.16158228,  0.04872749, -0.02086745,\n",
      "       -0.11526398,  0.        ,  0.        ], dtype=float32), array([ 0.00981636,  1.4195073 ,  0.17081414,  0.0583933 , -0.02808201,\n",
      "       -0.14430468,  0.        ,  0.        ], dtype=float32), array([ 0.01145172,  1.4202244 ,  0.17083533,  0.03171718, -0.03529498,\n",
      "       -0.14427301,  0.        ,  0.        ], dtype=float32), array([ 0.01308746,  1.4203422 ,  0.17085637,  0.00504831, -0.04250716,\n",
      "       -0.14425674,  0.        ,  0.        ], dtype=float32)]\n",
      "9\n",
      "[array([ 0.00163717,  1.4129504 ,  0.165805  ,  0.09023532, -0.0018902 ,\n",
      "       -0.03755725,  0.        ,  0.        ], dtype=float32), array([ 0.0033493 ,  1.4144068 ,  0.17500368,  0.06472376, -0.00563567,\n",
      "       -0.07491585,  0.        ,  0.        ], dtype=float32), array([ 0.00496588,  1.4160489 ,  0.16591594,  0.07295343, -0.00985315,\n",
      "       -0.08435733,  0.        ,  0.        ], dtype=float32), array([ 0.00662374,  1.4170928 ,  0.17109025,  0.04635807, -0.01510478,\n",
      "       -0.10504226,  0.        ,  0.        ], dtype=float32), array([ 0.00818119,  1.4181907 ,  0.16158228,  0.04872749, -0.02086745,\n",
      "       -0.11526398,  0.        ,  0.        ], dtype=float32), array([ 0.00981636,  1.4195073 ,  0.17081414,  0.0583933 , -0.02808201,\n",
      "       -0.14430468,  0.        ,  0.        ], dtype=float32), array([ 0.01145172,  1.4202244 ,  0.17083533,  0.03171718, -0.03529498,\n",
      "       -0.14427301,  0.        ,  0.        ], dtype=float32), array([ 0.01308746,  1.4203422 ,  0.17085637,  0.00504831, -0.04250716,\n",
      "       -0.14425674,  0.        ,  0.        ], dtype=float32), array([ 0.0148325 ,  1.4206448 ,  0.18137029,  0.01323786, -0.04930521,\n",
      "       -0.13597329,  0.        ,  0.        ], dtype=float32)]\n",
      "tf.Tensor([4 8], shape=(2,), dtype=int32)\n",
      "[array([ 0.00981636,  1.4195073 ,  0.17081414,  0.0583933 , -0.02808201,\n",
      "       -0.14430468,  0.        ,  0.        ], dtype=float32), array([ 0.01145172,  1.4202244 ,  0.17083533,  0.03171718, -0.03529498,\n",
      "       -0.14427301,  0.        ,  0.        ], dtype=float32), array([ 0.01308746,  1.4203422 ,  0.17085637,  0.00504831, -0.04250716,\n",
      "       -0.14425674,  0.        ,  0.        ], dtype=float32), array([ 0.0148325 ,  1.4206448 ,  0.18137029,  0.01323786, -0.04930521,\n",
      "       -0.13597329,  0.        ,  0.        ], dtype=float32)]\n",
      "10\n",
      "[array([ 0.00163717,  1.4129504 ,  0.165805  ,  0.09023532, -0.0018902 ,\n",
      "       -0.03755725,  0.        ,  0.        ], dtype=float32), array([ 0.0033493 ,  1.4144068 ,  0.17500368,  0.06472376, -0.00563567,\n",
      "       -0.07491585,  0.        ,  0.        ], dtype=float32), array([ 0.00496588,  1.4160489 ,  0.16591594,  0.07295343, -0.00985315,\n",
      "       -0.08435733,  0.        ,  0.        ], dtype=float32), array([ 0.00662374,  1.4170928 ,  0.17109025,  0.04635807, -0.01510478,\n",
      "       -0.10504226,  0.        ,  0.        ], dtype=float32), array([ 0.00818119,  1.4181907 ,  0.16158228,  0.04872749, -0.02086745,\n",
      "       -0.11526398,  0.        ,  0.        ], dtype=float32), array([ 0.00981636,  1.4195073 ,  0.17081414,  0.0583933 , -0.02808201,\n",
      "       -0.14430468,  0.        ,  0.        ], dtype=float32), array([ 0.01145172,  1.4202244 ,  0.17083533,  0.03171718, -0.03529498,\n",
      "       -0.14427301,  0.        ,  0.        ], dtype=float32), array([ 0.01308746,  1.4203422 ,  0.17085637,  0.00504831, -0.04250716,\n",
      "       -0.14425674,  0.        ,  0.        ], dtype=float32), array([ 0.0148325 ,  1.4206448 ,  0.18137029,  0.01323786, -0.04930521,\n",
      "       -0.13597329,  0.        ,  0.        ], dtype=float32), array([ 0.01657763,  1.4203478 ,  0.18138938, -0.01344071, -0.05610248,\n",
      "       -0.13595809,  0.        ,  0.        ], dtype=float32)]\n",
      "tf.Tensor([4 8], shape=(2,), dtype=int32)\n",
      "[array([ 0.01145172,  1.4202244 ,  0.17083533,  0.03171718, -0.03529498,\n",
      "       -0.14427301,  0.        ,  0.        ], dtype=float32), array([ 0.01308746,  1.4203422 ,  0.17085637,  0.00504831, -0.04250716,\n",
      "       -0.14425674,  0.        ,  0.        ], dtype=float32), array([ 0.0148325 ,  1.4206448 ,  0.18137029,  0.01323786, -0.04930521,\n",
      "       -0.13597329,  0.        ,  0.        ], dtype=float32), array([ 0.01657763,  1.4203478 ,  0.18138938, -0.01344071, -0.05610248,\n",
      "       -0.13595809,  0.        ,  0.        ], dtype=float32)]\n",
      "11\n",
      "[array([ 0.00163717,  1.4129504 ,  0.165805  ,  0.09023532, -0.0018902 ,\n",
      "       -0.03755725,  0.        ,  0.        ], dtype=float32), array([ 0.0033493 ,  1.4144068 ,  0.17500368,  0.06472376, -0.00563567,\n",
      "       -0.07491585,  0.        ,  0.        ], dtype=float32), array([ 0.00496588,  1.4160489 ,  0.16591594,  0.07295343, -0.00985315,\n",
      "       -0.08435733,  0.        ,  0.        ], dtype=float32), array([ 0.00662374,  1.4170928 ,  0.17109025,  0.04635807, -0.01510478,\n",
      "       -0.10504226,  0.        ,  0.        ], dtype=float32), array([ 0.00818119,  1.4181907 ,  0.16158228,  0.04872749, -0.02086745,\n",
      "       -0.11526398,  0.        ,  0.        ], dtype=float32), array([ 0.00981636,  1.4195073 ,  0.17081414,  0.0583933 , -0.02808201,\n",
      "       -0.14430468,  0.        ,  0.        ], dtype=float32), array([ 0.01145172,  1.4202244 ,  0.17083533,  0.03171718, -0.03529498,\n",
      "       -0.14427301,  0.        ,  0.        ], dtype=float32), array([ 0.01308746,  1.4203422 ,  0.17085637,  0.00504831, -0.04250716,\n",
      "       -0.14425674,  0.        ,  0.        ], dtype=float32), array([ 0.0148325 ,  1.4206448 ,  0.18137029,  0.01323786, -0.04930521,\n",
      "       -0.13597329,  0.        ,  0.        ], dtype=float32), array([ 0.01657763,  1.4203478 ,  0.18138938, -0.01344071, -0.05610248,\n",
      "       -0.13595809,  0.        ,  0.        ], dtype=float32), array([ 0.01832313,  1.4194515 ,  0.18140921, -0.04010994, -0.06289854,\n",
      "       -0.13593382,  0.        ,  0.        ], dtype=float32)]\n",
      "tf.Tensor([4 8], shape=(2,), dtype=int32)\n",
      "[array([ 0.01308746,  1.4203422 ,  0.17085637,  0.00504831, -0.04250716,\n",
      "       -0.14425674,  0.        ,  0.        ], dtype=float32), array([ 0.0148325 ,  1.4206448 ,  0.18137029,  0.01323786, -0.04930521,\n",
      "       -0.13597329,  0.        ,  0.        ], dtype=float32), array([ 0.01657763,  1.4203478 ,  0.18138938, -0.01344071, -0.05610248,\n",
      "       -0.13595809,  0.        ,  0.        ], dtype=float32), array([ 0.01832313,  1.4194515 ,  0.18140921, -0.04010994, -0.06289854,\n",
      "       -0.13593382,  0.        ,  0.        ], dtype=float32)]\n",
      "12\n",
      "[array([ 0.00163717,  1.4129504 ,  0.165805  ,  0.09023532, -0.0018902 ,\n",
      "       -0.03755725,  0.        ,  0.        ], dtype=float32), array([ 0.0033493 ,  1.4144068 ,  0.17500368,  0.06472376, -0.00563567,\n",
      "       -0.07491585,  0.        ,  0.        ], dtype=float32), array([ 0.00496588,  1.4160489 ,  0.16591594,  0.07295343, -0.00985315,\n",
      "       -0.08435733,  0.        ,  0.        ], dtype=float32), array([ 0.00662374,  1.4170928 ,  0.17109025,  0.04635807, -0.01510478,\n",
      "       -0.10504226,  0.        ,  0.        ], dtype=float32), array([ 0.00818119,  1.4181907 ,  0.16158228,  0.04872749, -0.02086745,\n",
      "       -0.11526398,  0.        ,  0.        ], dtype=float32), array([ 0.00981636,  1.4195073 ,  0.17081414,  0.0583933 , -0.02808201,\n",
      "       -0.14430468,  0.        ,  0.        ], dtype=float32), array([ 0.01145172,  1.4202244 ,  0.17083533,  0.03171718, -0.03529498,\n",
      "       -0.14427301,  0.        ,  0.        ], dtype=float32), array([ 0.01308746,  1.4203422 ,  0.17085637,  0.00504831, -0.04250716,\n",
      "       -0.14425674,  0.        ,  0.        ], dtype=float32), array([ 0.0148325 ,  1.4206448 ,  0.18137029,  0.01323786, -0.04930521,\n",
      "       -0.13597329,  0.        ,  0.        ], dtype=float32), array([ 0.01657763,  1.4203478 ,  0.18138938, -0.01344071, -0.05610248,\n",
      "       -0.13595809,  0.        ,  0.        ], dtype=float32), array([ 0.01832313,  1.4194515 ,  0.18140921, -0.04010994, -0.06289854,\n",
      "       -0.13593382,  0.        ,  0.        ], dtype=float32), array([ 0.02004051,  1.4186051 ,  0.17885709, -0.03793951, -0.06995627,\n",
      "       -0.14116722,  0.        ,  0.        ], dtype=float32)]\n",
      "tf.Tensor([4 8], shape=(2,), dtype=int32)\n",
      "[array([ 0.0148325 ,  1.4206448 ,  0.18137029,  0.01323786, -0.04930521,\n",
      "       -0.13597329,  0.        ,  0.        ], dtype=float32), array([ 0.01657763,  1.4203478 ,  0.18138938, -0.01344071, -0.05610248,\n",
      "       -0.13595809,  0.        ,  0.        ], dtype=float32), array([ 0.01832313,  1.4194515 ,  0.18140921, -0.04010994, -0.06289854,\n",
      "       -0.13593382,  0.        ,  0.        ], dtype=float32), array([ 0.02004051,  1.4186051 ,  0.17885709, -0.03793951, -0.06995627,\n",
      "       -0.14116722,  0.        ,  0.        ], dtype=float32)]\n",
      "13\n",
      "[array([ 0.00163717,  1.4129504 ,  0.165805  ,  0.09023532, -0.0018902 ,\n",
      "       -0.03755725,  0.        ,  0.        ], dtype=float32), array([ 0.0033493 ,  1.4144068 ,  0.17500368,  0.06472376, -0.00563567,\n",
      "       -0.07491585,  0.        ,  0.        ], dtype=float32), array([ 0.00496588,  1.4160489 ,  0.16591594,  0.07295343, -0.00985315,\n",
      "       -0.08435733,  0.        ,  0.        ], dtype=float32), array([ 0.00662374,  1.4170928 ,  0.17109025,  0.04635807, -0.01510478,\n",
      "       -0.10504226,  0.        ,  0.        ], dtype=float32), array([ 0.00818119,  1.4181907 ,  0.16158228,  0.04872749, -0.02086745,\n",
      "       -0.11526398,  0.        ,  0.        ], dtype=float32), array([ 0.00981636,  1.4195073 ,  0.17081414,  0.0583933 , -0.02808201,\n",
      "       -0.14430468,  0.        ,  0.        ], dtype=float32), array([ 0.01145172,  1.4202244 ,  0.17083533,  0.03171718, -0.03529498,\n",
      "       -0.14427301,  0.        ,  0.        ], dtype=float32), array([ 0.01308746,  1.4203422 ,  0.17085637,  0.00504831, -0.04250716,\n",
      "       -0.14425674,  0.        ,  0.        ], dtype=float32), array([ 0.0148325 ,  1.4206448 ,  0.18137029,  0.01323786, -0.04930521,\n",
      "       -0.13597329,  0.        ,  0.        ], dtype=float32), array([ 0.01657763,  1.4203478 ,  0.18138938, -0.01344071, -0.05610248,\n",
      "       -0.13595809,  0.        ,  0.        ], dtype=float32), array([ 0.01832313,  1.4194515 ,  0.18140921, -0.04010994, -0.06289854,\n",
      "       -0.13593382,  0.        ,  0.        ], dtype=float32), array([ 0.02004051,  1.4186051 ,  0.17885709, -0.03793951, -0.06995627,\n",
      "       -0.14116722,  0.        ,  0.        ], dtype=float32), array([ 0.02168207,  1.4175704 ,  0.17172542, -0.04635783, -0.07746167,\n",
      "       -0.15012197,  0.        ,  0.        ], dtype=float32)]\n",
      "tf.Tensor([4 8], shape=(2,), dtype=int32)\n",
      "[array([ 0.01657763,  1.4203478 ,  0.18138938, -0.01344071, -0.05610248,\n",
      "       -0.13595809,  0.        ,  0.        ], dtype=float32), array([ 0.01832313,  1.4194515 ,  0.18140921, -0.04010994, -0.06289854,\n",
      "       -0.13593382,  0.        ,  0.        ], dtype=float32), array([ 0.02004051,  1.4186051 ,  0.17885709, -0.03793951, -0.06995627,\n",
      "       -0.14116722,  0.        ,  0.        ], dtype=float32), array([ 0.02168207,  1.4175704 ,  0.17172542, -0.04635783, -0.07746167,\n",
      "       -0.15012197,  0.        ,  0.        ], dtype=float32)]\n",
      "14\n",
      "[array([ 0.00163717,  1.4129504 ,  0.165805  ,  0.09023532, -0.0018902 ,\n",
      "       -0.03755725,  0.        ,  0.        ], dtype=float32), array([ 0.0033493 ,  1.4144068 ,  0.17500368,  0.06472376, -0.00563567,\n",
      "       -0.07491585,  0.        ,  0.        ], dtype=float32), array([ 0.00496588,  1.4160489 ,  0.16591594,  0.07295343, -0.00985315,\n",
      "       -0.08435733,  0.        ,  0.        ], dtype=float32), array([ 0.00662374,  1.4170928 ,  0.17109025,  0.04635807, -0.01510478,\n",
      "       -0.10504226,  0.        ,  0.        ], dtype=float32), array([ 0.00818119,  1.4181907 ,  0.16158228,  0.04872749, -0.02086745,\n",
      "       -0.11526398,  0.        ,  0.        ], dtype=float32), array([ 0.00981636,  1.4195073 ,  0.17081414,  0.0583933 , -0.02808201,\n",
      "       -0.14430468,  0.        ,  0.        ], dtype=float32), array([ 0.01145172,  1.4202244 ,  0.17083533,  0.03171718, -0.03529498,\n",
      "       -0.14427301,  0.        ,  0.        ], dtype=float32), array([ 0.01308746,  1.4203422 ,  0.17085637,  0.00504831, -0.04250716,\n",
      "       -0.14425674,  0.        ,  0.        ], dtype=float32), array([ 0.0148325 ,  1.4206448 ,  0.18137029,  0.01323786, -0.04930521,\n",
      "       -0.13597329,  0.        ,  0.        ], dtype=float32), array([ 0.01657763,  1.4203478 ,  0.18138938, -0.01344071, -0.05610248,\n",
      "       -0.13595809,  0.        ,  0.        ], dtype=float32), array([ 0.01832313,  1.4194515 ,  0.18140921, -0.04010994, -0.06289854,\n",
      "       -0.13593382,  0.        ,  0.        ], dtype=float32), array([ 0.02004051,  1.4186051 ,  0.17885709, -0.03793951, -0.06995627,\n",
      "       -0.14116722,  0.        ,  0.        ], dtype=float32), array([ 0.02168207,  1.4175704 ,  0.17172542, -0.04635783, -0.07746167,\n",
      "       -0.15012197,  0.        ,  0.        ], dtype=float32), array([ 0.02340326,  1.4165119 ,  0.1794485 , -0.0474439 , -0.08473222,\n",
      "       -0.1454241 ,  0.        ,  0.        ], dtype=float32)]\n",
      "tf.Tensor([4 8], shape=(2,), dtype=int32)\n",
      "[array([ 0.01832313,  1.4194515 ,  0.18140921, -0.04010994, -0.06289854,\n",
      "       -0.13593382,  0.        ,  0.        ], dtype=float32), array([ 0.02004051,  1.4186051 ,  0.17885709, -0.03793951, -0.06995627,\n",
      "       -0.14116722,  0.        ,  0.        ], dtype=float32), array([ 0.02168207,  1.4175704 ,  0.17172542, -0.04635783, -0.07746167,\n",
      "       -0.15012197,  0.        ,  0.        ], dtype=float32), array([ 0.02340326,  1.4165119 ,  0.1794485 , -0.0474439 , -0.08473222,\n",
      "       -0.1454241 ,  0.        ,  0.        ], dtype=float32)]\n",
      "15\n",
      "[array([ 0.00163717,  1.4129504 ,  0.165805  ,  0.09023532, -0.0018902 ,\n",
      "       -0.03755725,  0.        ,  0.        ], dtype=float32), array([ 0.0033493 ,  1.4144068 ,  0.17500368,  0.06472376, -0.00563567,\n",
      "       -0.07491585,  0.        ,  0.        ], dtype=float32), array([ 0.00496588,  1.4160489 ,  0.16591594,  0.07295343, -0.00985315,\n",
      "       -0.08435733,  0.        ,  0.        ], dtype=float32), array([ 0.00662374,  1.4170928 ,  0.17109025,  0.04635807, -0.01510478,\n",
      "       -0.10504226,  0.        ,  0.        ], dtype=float32), array([ 0.00818119,  1.4181907 ,  0.16158228,  0.04872749, -0.02086745,\n",
      "       -0.11526398,  0.        ,  0.        ], dtype=float32), array([ 0.00981636,  1.4195073 ,  0.17081414,  0.0583933 , -0.02808201,\n",
      "       -0.14430468,  0.        ,  0.        ], dtype=float32), array([ 0.01145172,  1.4202244 ,  0.17083533,  0.03171718, -0.03529498,\n",
      "       -0.14427301,  0.        ,  0.        ], dtype=float32), array([ 0.01308746,  1.4203422 ,  0.17085637,  0.00504831, -0.04250716,\n",
      "       -0.14425674,  0.        ,  0.        ], dtype=float32), array([ 0.0148325 ,  1.4206448 ,  0.18137029,  0.01323786, -0.04930521,\n",
      "       -0.13597329,  0.        ,  0.        ], dtype=float32), array([ 0.01657763,  1.4203478 ,  0.18138938, -0.01344071, -0.05610248,\n",
      "       -0.13595809,  0.        ,  0.        ], dtype=float32), array([ 0.01832313,  1.4194515 ,  0.18140921, -0.04010994, -0.06289854,\n",
      "       -0.13593382,  0.        ,  0.        ], dtype=float32), array([ 0.02004051,  1.4186051 ,  0.17885709, -0.03793951, -0.06995627,\n",
      "       -0.14116722,  0.        ,  0.        ], dtype=float32), array([ 0.02168207,  1.4175704 ,  0.17172542, -0.04635783, -0.07746167,\n",
      "       -0.15012197,  0.        ,  0.        ], dtype=float32), array([ 0.02340326,  1.4165119 ,  0.1794485 , -0.0474439 , -0.08473222,\n",
      "       -0.1454241 ,  0.        ,  0.        ], dtype=float32), array([ 0.02521744,  1.4154747 ,  0.1884745 , -0.04651706, -0.09173133,\n",
      "       -0.13999477,  0.        ,  0.        ], dtype=float32)]\n",
      "tf.Tensor([4 8], shape=(2,), dtype=int32)\n",
      "[array([ 0.02004051,  1.4186051 ,  0.17885709, -0.03793951, -0.06995627,\n",
      "       -0.14116722,  0.        ,  0.        ], dtype=float32), array([ 0.02168207,  1.4175704 ,  0.17172542, -0.04635783, -0.07746167,\n",
      "       -0.15012197,  0.        ,  0.        ], dtype=float32), array([ 0.02340326,  1.4165119 ,  0.1794485 , -0.0474439 , -0.08473222,\n",
      "       -0.1454241 ,  0.        ,  0.        ], dtype=float32), array([ 0.02521744,  1.4154747 ,  0.1884745 , -0.04651706, -0.09173133,\n",
      "       -0.13999477,  0.        ,  0.        ], dtype=float32)]\n",
      "16\n",
      "[array([ 0.00163717,  1.4129504 ,  0.165805  ,  0.09023532, -0.0018902 ,\n",
      "       -0.03755725,  0.        ,  0.        ], dtype=float32), array([ 0.0033493 ,  1.4144068 ,  0.17500368,  0.06472376, -0.00563567,\n",
      "       -0.07491585,  0.        ,  0.        ], dtype=float32), array([ 0.00496588,  1.4160489 ,  0.16591594,  0.07295343, -0.00985315,\n",
      "       -0.08435733,  0.        ,  0.        ], dtype=float32), array([ 0.00662374,  1.4170928 ,  0.17109025,  0.04635807, -0.01510478,\n",
      "       -0.10504226,  0.        ,  0.        ], dtype=float32), array([ 0.00818119,  1.4181907 ,  0.16158228,  0.04872749, -0.02086745,\n",
      "       -0.11526398,  0.        ,  0.        ], dtype=float32), array([ 0.00981636,  1.4195073 ,  0.17081414,  0.0583933 , -0.02808201,\n",
      "       -0.14430468,  0.        ,  0.        ], dtype=float32), array([ 0.01145172,  1.4202244 ,  0.17083533,  0.03171718, -0.03529498,\n",
      "       -0.14427301,  0.        ,  0.        ], dtype=float32), array([ 0.01308746,  1.4203422 ,  0.17085637,  0.00504831, -0.04250716,\n",
      "       -0.14425674,  0.        ,  0.        ], dtype=float32), array([ 0.0148325 ,  1.4206448 ,  0.18137029,  0.01323786, -0.04930521,\n",
      "       -0.13597329,  0.        ,  0.        ], dtype=float32), array([ 0.01657763,  1.4203478 ,  0.18138938, -0.01344071, -0.05610248,\n",
      "       -0.13595809,  0.        ,  0.        ], dtype=float32), array([ 0.01832313,  1.4194515 ,  0.18140921, -0.04010994, -0.06289854,\n",
      "       -0.13593382,  0.        ,  0.        ], dtype=float32), array([ 0.02004051,  1.4186051 ,  0.17885709, -0.03793951, -0.06995627,\n",
      "       -0.14116722,  0.        ,  0.        ], dtype=float32), array([ 0.02168207,  1.4175704 ,  0.17172542, -0.04635783, -0.07746167,\n",
      "       -0.15012197,  0.        ,  0.        ], dtype=float32), array([ 0.02340326,  1.4165119 ,  0.1794485 , -0.0474439 , -0.08473222,\n",
      "       -0.1454241 ,  0.        ,  0.        ], dtype=float32), array([ 0.02521744,  1.4154747 ,  0.1884745 , -0.04651706, -0.09173133,\n",
      "       -0.13999477,  0.        ,  0.        ], dtype=float32), array([ 0.0270319 ,  1.413838  ,  0.18849362, -0.07319318, -0.09872948,\n",
      "       -0.13997564,  0.        ,  0.        ], dtype=float32)]\n",
      "tf.Tensor([4 8], shape=(2,), dtype=int32)\n",
      "[array([ 0.02168207,  1.4175704 ,  0.17172542, -0.04635783, -0.07746167,\n",
      "       -0.15012197,  0.        ,  0.        ], dtype=float32), array([ 0.02340326,  1.4165119 ,  0.1794485 , -0.0474439 , -0.08473222,\n",
      "       -0.1454241 ,  0.        ,  0.        ], dtype=float32), array([ 0.02521744,  1.4154747 ,  0.1884745 , -0.04651706, -0.09173133,\n",
      "       -0.13999477,  0.        ,  0.        ], dtype=float32), array([ 0.0270319 ,  1.413838  ,  0.18849362, -0.07319318, -0.09872948,\n",
      "       -0.13997564,  0.        ,  0.        ], dtype=float32)]\n",
      "17\n",
      "[array([ 0.00163717,  1.4129504 ,  0.165805  ,  0.09023532, -0.0018902 ,\n",
      "       -0.03755725,  0.        ,  0.        ], dtype=float32), array([ 0.0033493 ,  1.4144068 ,  0.17500368,  0.06472376, -0.00563567,\n",
      "       -0.07491585,  0.        ,  0.        ], dtype=float32), array([ 0.00496588,  1.4160489 ,  0.16591594,  0.07295343, -0.00985315,\n",
      "       -0.08435733,  0.        ,  0.        ], dtype=float32), array([ 0.00662374,  1.4170928 ,  0.17109025,  0.04635807, -0.01510478,\n",
      "       -0.10504226,  0.        ,  0.        ], dtype=float32), array([ 0.00818119,  1.4181907 ,  0.16158228,  0.04872749, -0.02086745,\n",
      "       -0.11526398,  0.        ,  0.        ], dtype=float32), array([ 0.00981636,  1.4195073 ,  0.17081414,  0.0583933 , -0.02808201,\n",
      "       -0.14430468,  0.        ,  0.        ], dtype=float32), array([ 0.01145172,  1.4202244 ,  0.17083533,  0.03171718, -0.03529498,\n",
      "       -0.14427301,  0.        ,  0.        ], dtype=float32), array([ 0.01308746,  1.4203422 ,  0.17085637,  0.00504831, -0.04250716,\n",
      "       -0.14425674,  0.        ,  0.        ], dtype=float32), array([ 0.0148325 ,  1.4206448 ,  0.18137029,  0.01323786, -0.04930521,\n",
      "       -0.13597329,  0.        ,  0.        ], dtype=float32), array([ 0.01657763,  1.4203478 ,  0.18138938, -0.01344071, -0.05610248,\n",
      "       -0.13595809,  0.        ,  0.        ], dtype=float32), array([ 0.01832313,  1.4194515 ,  0.18140921, -0.04010994, -0.06289854,\n",
      "       -0.13593382,  0.        ,  0.        ], dtype=float32), array([ 0.02004051,  1.4186051 ,  0.17885709, -0.03793951, -0.06995627,\n",
      "       -0.14116722,  0.        ,  0.        ], dtype=float32), array([ 0.02168207,  1.4175704 ,  0.17172542, -0.04635783, -0.07746167,\n",
      "       -0.15012197,  0.        ,  0.        ], dtype=float32), array([ 0.02340326,  1.4165119 ,  0.1794485 , -0.0474439 , -0.08473222,\n",
      "       -0.1454241 ,  0.        ,  0.        ], dtype=float32), array([ 0.02521744,  1.4154747 ,  0.1884745 , -0.04651706, -0.09173133,\n",
      "       -0.13999477,  0.        ,  0.        ], dtype=float32), array([ 0.0270319 ,  1.413838  ,  0.18849362, -0.07319318, -0.09872948,\n",
      "       -0.13997564,  0.        ,  0.        ], dtype=float32), array([ 0.02885647,  1.4122144 ,  0.18827246, -0.07255664, -0.10451551,\n",
      "       -0.11573099,  0.        ,  0.        ], dtype=float32)]\n",
      "tf.Tensor([4 8], shape=(2,), dtype=int32)\n",
      "[array([ 0.02340326,  1.4165119 ,  0.1794485 , -0.0474439 , -0.08473222,\n",
      "       -0.1454241 ,  0.        ,  0.        ], dtype=float32), array([ 0.02521744,  1.4154747 ,  0.1884745 , -0.04651706, -0.09173133,\n",
      "       -0.13999477,  0.        ,  0.        ], dtype=float32), array([ 0.0270319 ,  1.413838  ,  0.18849362, -0.07319318, -0.09872948,\n",
      "       -0.13997564,  0.        ,  0.        ], dtype=float32), array([ 0.02885647,  1.4122144 ,  0.18827246, -0.07255664, -0.10451551,\n",
      "       -0.11573099,  0.        ,  0.        ], dtype=float32)]\n",
      "18\n",
      "[array([ 0.00163717,  1.4129504 ,  0.165805  ,  0.09023532, -0.0018902 ,\n",
      "       -0.03755725,  0.        ,  0.        ], dtype=float32), array([ 0.0033493 ,  1.4144068 ,  0.17500368,  0.06472376, -0.00563567,\n",
      "       -0.07491585,  0.        ,  0.        ], dtype=float32), array([ 0.00496588,  1.4160489 ,  0.16591594,  0.07295343, -0.00985315,\n",
      "       -0.08435733,  0.        ,  0.        ], dtype=float32), array([ 0.00662374,  1.4170928 ,  0.17109025,  0.04635807, -0.01510478,\n",
      "       -0.10504226,  0.        ,  0.        ], dtype=float32), array([ 0.00818119,  1.4181907 ,  0.16158228,  0.04872749, -0.02086745,\n",
      "       -0.11526398,  0.        ,  0.        ], dtype=float32), array([ 0.00981636,  1.4195073 ,  0.17081414,  0.0583933 , -0.02808201,\n",
      "       -0.14430468,  0.        ,  0.        ], dtype=float32), array([ 0.01145172,  1.4202244 ,  0.17083533,  0.03171718, -0.03529498,\n",
      "       -0.14427301,  0.        ,  0.        ], dtype=float32), array([ 0.01308746,  1.4203422 ,  0.17085637,  0.00504831, -0.04250716,\n",
      "       -0.14425674,  0.        ,  0.        ], dtype=float32), array([ 0.0148325 ,  1.4206448 ,  0.18137029,  0.01323786, -0.04930521,\n",
      "       -0.13597329,  0.        ,  0.        ], dtype=float32), array([ 0.01657763,  1.4203478 ,  0.18138938, -0.01344071, -0.05610248,\n",
      "       -0.13595809,  0.        ,  0.        ], dtype=float32), array([ 0.01832313,  1.4194515 ,  0.18140921, -0.04010994, -0.06289854,\n",
      "       -0.13593382,  0.        ,  0.        ], dtype=float32), array([ 0.02004051,  1.4186051 ,  0.17885709, -0.03793951, -0.06995627,\n",
      "       -0.14116722,  0.        ,  0.        ], dtype=float32), array([ 0.02168207,  1.4175704 ,  0.17172542, -0.04635783, -0.07746167,\n",
      "       -0.15012197,  0.        ,  0.        ], dtype=float32), array([ 0.02340326,  1.4165119 ,  0.1794485 , -0.0474439 , -0.08473222,\n",
      "       -0.1454241 ,  0.        ,  0.        ], dtype=float32), array([ 0.02521744,  1.4154747 ,  0.1884745 , -0.04651706, -0.09173133,\n",
      "       -0.13999477,  0.        ,  0.        ], dtype=float32), array([ 0.0270319 ,  1.413838  ,  0.18849362, -0.07319318, -0.09872948,\n",
      "       -0.13997564,  0.        ,  0.        ], dtype=float32), array([ 0.02885647,  1.4122144 ,  0.18827246, -0.07255664, -0.10451551,\n",
      "       -0.11573099,  0.        ,  0.        ], dtype=float32), array([ 0.03076677,  1.4104848 ,  0.19660668, -0.077275  , -0.11006298,\n",
      "       -0.11095947,  0.        ,  0.        ], dtype=float32)]\n",
      "tf.Tensor([4 8], shape=(2,), dtype=int32)\n",
      "[array([ 0.02521744,  1.4154747 ,  0.1884745 , -0.04651706, -0.09173133,\n",
      "       -0.13999477,  0.        ,  0.        ], dtype=float32), array([ 0.0270319 ,  1.413838  ,  0.18849362, -0.07319318, -0.09872948,\n",
      "       -0.13997564,  0.        ,  0.        ], dtype=float32), array([ 0.02885647,  1.4122144 ,  0.18827246, -0.07255664, -0.10451551,\n",
      "       -0.11573099,  0.        ,  0.        ], dtype=float32), array([ 0.03076677,  1.4104848 ,  0.19660668, -0.077275  , -0.11006298,\n",
      "       -0.11095947,  0.        ,  0.        ], dtype=float32)]\n",
      "19\n",
      "[array([ 0.00163717,  1.4129504 ,  0.165805  ,  0.09023532, -0.0018902 ,\n",
      "       -0.03755725,  0.        ,  0.        ], dtype=float32), array([ 0.0033493 ,  1.4144068 ,  0.17500368,  0.06472376, -0.00563567,\n",
      "       -0.07491585,  0.        ,  0.        ], dtype=float32), array([ 0.00496588,  1.4160489 ,  0.16591594,  0.07295343, -0.00985315,\n",
      "       -0.08435733,  0.        ,  0.        ], dtype=float32), array([ 0.00662374,  1.4170928 ,  0.17109025,  0.04635807, -0.01510478,\n",
      "       -0.10504226,  0.        ,  0.        ], dtype=float32), array([ 0.00818119,  1.4181907 ,  0.16158228,  0.04872749, -0.02086745,\n",
      "       -0.11526398,  0.        ,  0.        ], dtype=float32), array([ 0.00981636,  1.4195073 ,  0.17081414,  0.0583933 , -0.02808201,\n",
      "       -0.14430468,  0.        ,  0.        ], dtype=float32), array([ 0.01145172,  1.4202244 ,  0.17083533,  0.03171718, -0.03529498,\n",
      "       -0.14427301,  0.        ,  0.        ], dtype=float32), array([ 0.01308746,  1.4203422 ,  0.17085637,  0.00504831, -0.04250716,\n",
      "       -0.14425674,  0.        ,  0.        ], dtype=float32), array([ 0.0148325 ,  1.4206448 ,  0.18137029,  0.01323786, -0.04930521,\n",
      "       -0.13597329,  0.        ,  0.        ], dtype=float32), array([ 0.01657763,  1.4203478 ,  0.18138938, -0.01344071, -0.05610248,\n",
      "       -0.13595809,  0.        ,  0.        ], dtype=float32), array([ 0.01832313,  1.4194515 ,  0.18140921, -0.04010994, -0.06289854,\n",
      "       -0.13593382,  0.        ,  0.        ], dtype=float32), array([ 0.02004051,  1.4186051 ,  0.17885709, -0.03793951, -0.06995627,\n",
      "       -0.14116722,  0.        ,  0.        ], dtype=float32), array([ 0.02168207,  1.4175704 ,  0.17172542, -0.04635783, -0.07746167,\n",
      "       -0.15012197,  0.        ,  0.        ], dtype=float32), array([ 0.02340326,  1.4165119 ,  0.1794485 , -0.0474439 , -0.08473222,\n",
      "       -0.1454241 ,  0.        ,  0.        ], dtype=float32), array([ 0.02521744,  1.4154747 ,  0.1884745 , -0.04651706, -0.09173133,\n",
      "       -0.13999477,  0.        ,  0.        ], dtype=float32), array([ 0.0270319 ,  1.413838  ,  0.18849362, -0.07319318, -0.09872948,\n",
      "       -0.13997564,  0.        ,  0.        ], dtype=float32), array([ 0.02885647,  1.4122144 ,  0.18827246, -0.07255664, -0.10451551,\n",
      "       -0.11573099,  0.        ,  0.        ], dtype=float32), array([ 0.03076677,  1.4104848 ,  0.19660668, -0.077275  , -0.11006298,\n",
      "       -0.11095947,  0.        ,  0.        ], dtype=float32), array([ 0.03277826,  1.4089754 ,  0.20653772, -0.06749256, -0.11542024,\n",
      "       -0.10715486,  0.        ,  0.        ], dtype=float32)]\n",
      "tf.Tensor([4 8], shape=(2,), dtype=int32)\n",
      "[array([ 0.0270319 ,  1.413838  ,  0.18849362, -0.07319318, -0.09872948,\n",
      "       -0.13997564,  0.        ,  0.        ], dtype=float32), array([ 0.02885647,  1.4122144 ,  0.18827246, -0.07255664, -0.10451551,\n",
      "       -0.11573099,  0.        ,  0.        ], dtype=float32), array([ 0.03076677,  1.4104848 ,  0.19660668, -0.077275  , -0.11006298,\n",
      "       -0.11095947,  0.        ,  0.        ], dtype=float32), array([ 0.03277826,  1.4089754 ,  0.20653772, -0.06749256, -0.11542024,\n",
      "       -0.10715486,  0.        ,  0.        ], dtype=float32)]\n",
      "20\n",
      "[array([ 0.00163717,  1.4129504 ,  0.165805  ,  0.09023532, -0.0018902 ,\n",
      "       -0.03755725,  0.        ,  0.        ], dtype=float32), array([ 0.0033493 ,  1.4144068 ,  0.17500368,  0.06472376, -0.00563567,\n",
      "       -0.07491585,  0.        ,  0.        ], dtype=float32), array([ 0.00496588,  1.4160489 ,  0.16591594,  0.07295343, -0.00985315,\n",
      "       -0.08435733,  0.        ,  0.        ], dtype=float32), array([ 0.00662374,  1.4170928 ,  0.17109025,  0.04635807, -0.01510478,\n",
      "       -0.10504226,  0.        ,  0.        ], dtype=float32), array([ 0.00818119,  1.4181907 ,  0.16158228,  0.04872749, -0.02086745,\n",
      "       -0.11526398,  0.        ,  0.        ], dtype=float32), array([ 0.00981636,  1.4195073 ,  0.17081414,  0.0583933 , -0.02808201,\n",
      "       -0.14430468,  0.        ,  0.        ], dtype=float32), array([ 0.01145172,  1.4202244 ,  0.17083533,  0.03171718, -0.03529498,\n",
      "       -0.14427301,  0.        ,  0.        ], dtype=float32), array([ 0.01308746,  1.4203422 ,  0.17085637,  0.00504831, -0.04250716,\n",
      "       -0.14425674,  0.        ,  0.        ], dtype=float32), array([ 0.0148325 ,  1.4206448 ,  0.18137029,  0.01323786, -0.04930521,\n",
      "       -0.13597329,  0.        ,  0.        ], dtype=float32), array([ 0.01657763,  1.4203478 ,  0.18138938, -0.01344071, -0.05610248,\n",
      "       -0.13595809,  0.        ,  0.        ], dtype=float32), array([ 0.01832313,  1.4194515 ,  0.18140921, -0.04010994, -0.06289854,\n",
      "       -0.13593382,  0.        ,  0.        ], dtype=float32), array([ 0.02004051,  1.4186051 ,  0.17885709, -0.03793951, -0.06995627,\n",
      "       -0.14116722,  0.        ,  0.        ], dtype=float32), array([ 0.02168207,  1.4175704 ,  0.17172542, -0.04635783, -0.07746167,\n",
      "       -0.15012197,  0.        ,  0.        ], dtype=float32), array([ 0.02340326,  1.4165119 ,  0.1794485 , -0.0474439 , -0.08473222,\n",
      "       -0.1454241 ,  0.        ,  0.        ], dtype=float32), array([ 0.02521744,  1.4154747 ,  0.1884745 , -0.04651706, -0.09173133,\n",
      "       -0.13999477,  0.        ,  0.        ], dtype=float32), array([ 0.0270319 ,  1.413838  ,  0.18849362, -0.07319318, -0.09872948,\n",
      "       -0.13997564,  0.        ,  0.        ], dtype=float32), array([ 0.02885647,  1.4122144 ,  0.18827246, -0.07255664, -0.10451551,\n",
      "       -0.11573099,  0.        ,  0.        ], dtype=float32), array([ 0.03076677,  1.4104848 ,  0.19660668, -0.077275  , -0.11006298,\n",
      "       -0.11095947,  0.        ,  0.        ], dtype=float32), array([ 0.03277826,  1.4089754 ,  0.20653772, -0.06749256, -0.11542024,\n",
      "       -0.10715486,  0.        ,  0.        ], dtype=float32), array([ 0.03480377,  1.4072781 ,  0.20801303, -0.0758668 , -0.12086052,\n",
      "       -0.10881545,  0.        ,  0.        ], dtype=float32)]\n",
      "tf.Tensor([4 8], shape=(2,), dtype=int32)\n",
      "[array([ 0.02885647,  1.4122144 ,  0.18827246, -0.07255664, -0.10451551,\n",
      "       -0.11573099,  0.        ,  0.        ], dtype=float32), array([ 0.03076677,  1.4104848 ,  0.19660668, -0.077275  , -0.11006298,\n",
      "       -0.11095947,  0.        ,  0.        ], dtype=float32), array([ 0.03277826,  1.4089754 ,  0.20653772, -0.06749256, -0.11542024,\n",
      "       -0.10715486,  0.        ,  0.        ], dtype=float32), array([ 0.03480377,  1.4072781 ,  0.20801303, -0.0758668 , -0.12086052,\n",
      "       -0.10881545,  0.        ,  0.        ], dtype=float32)]\n",
      "1\n",
      "[array([ 0.00163717,  1.4129504 ,  0.165805  ,  0.09023532, -0.0018902 ,\n",
      "       -0.03755725,  0.        ,  0.        ], dtype=float32), array([ 0.0033493 ,  1.4144068 ,  0.17500368,  0.06472376, -0.00563567,\n",
      "       -0.07491585,  0.        ,  0.        ], dtype=float32), array([ 0.00496588,  1.4160489 ,  0.16591594,  0.07295343, -0.00985315,\n",
      "       -0.08435733,  0.        ,  0.        ], dtype=float32), array([ 0.00662374,  1.4170928 ,  0.17109025,  0.04635807, -0.01510478,\n",
      "       -0.10504226,  0.        ,  0.        ], dtype=float32), array([ 0.00818119,  1.4181907 ,  0.16158228,  0.04872749, -0.02086745,\n",
      "       -0.11526398,  0.        ,  0.        ], dtype=float32), array([ 0.00981636,  1.4195073 ,  0.17081414,  0.0583933 , -0.02808201,\n",
      "       -0.14430468,  0.        ,  0.        ], dtype=float32), array([ 0.01145172,  1.4202244 ,  0.17083533,  0.03171718, -0.03529498,\n",
      "       -0.14427301,  0.        ,  0.        ], dtype=float32), array([ 0.01308746,  1.4203422 ,  0.17085637,  0.00504831, -0.04250716,\n",
      "       -0.14425674,  0.        ,  0.        ], dtype=float32), array([ 0.0148325 ,  1.4206448 ,  0.18137029,  0.01323786, -0.04930521,\n",
      "       -0.13597329,  0.        ,  0.        ], dtype=float32), array([ 0.01657763,  1.4203478 ,  0.18138938, -0.01344071, -0.05610248,\n",
      "       -0.13595809,  0.        ,  0.        ], dtype=float32), array([ 0.01832313,  1.4194515 ,  0.18140921, -0.04010994, -0.06289854,\n",
      "       -0.13593382,  0.        ,  0.        ], dtype=float32), array([ 0.02004051,  1.4186051 ,  0.17885709, -0.03793951, -0.06995627,\n",
      "       -0.14116722,  0.        ,  0.        ], dtype=float32), array([ 0.02168207,  1.4175704 ,  0.17172542, -0.04635783, -0.07746167,\n",
      "       -0.15012197,  0.        ,  0.        ], dtype=float32), array([ 0.02340326,  1.4165119 ,  0.1794485 , -0.0474439 , -0.08473222,\n",
      "       -0.1454241 ,  0.        ,  0.        ], dtype=float32), array([ 0.02521744,  1.4154747 ,  0.1884745 , -0.04651706, -0.09173133,\n",
      "       -0.13999477,  0.        ,  0.        ], dtype=float32), array([ 0.0270319 ,  1.413838  ,  0.18849362, -0.07319318, -0.09872948,\n",
      "       -0.13997564,  0.        ,  0.        ], dtype=float32), array([ 0.02885647,  1.4122144 ,  0.18827246, -0.07255664, -0.10451551,\n",
      "       -0.11573099,  0.        ,  0.        ], dtype=float32), array([ 0.03076677,  1.4104848 ,  0.19660668, -0.077275  , -0.11006298,\n",
      "       -0.11095947,  0.        ,  0.        ], dtype=float32), array([ 0.03277826,  1.4089754 ,  0.20653772, -0.06749256, -0.11542024,\n",
      "       -0.10715486,  0.        ,  0.        ], dtype=float32), array([ 0.03480377,  1.4072781 ,  0.20801303, -0.0758668 , -0.12086052,\n",
      "       -0.10881545,  0.        ,  0.        ], dtype=float32), array([-1.1187553e-03,  1.4101703e+00, -1.1332862e-01, -3.3328544e-02,\n",
      "        1.3030873e-03,  2.5670657e-02,  0.0000000e+00,  0.0000000e+00],\n",
      "      dtype=float32)]\n",
      "tf.Tensor([0], shape=(1,), dtype=int32)\n",
      "[]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "{{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:CPU:0}} The first dimension of paddings must be the rank of inputs[2,2] [0] [Op:Pad]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\61417\\Documents\\Units\\thesis_preparation\\right_left_brain_rl\\experiment\\working\\learn_tensorflow\\learning_tensorflow_RL_PPO.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_PPO.ipynb#X52sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m agent \u001b[39m=\u001b[39m LSTMPPO(        \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_PPO.ipynb#X52sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     env_name \u001b[39m=\u001b[39m ENV,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_PPO.ipynb#X52sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     gamma \u001b[39m=\u001b[39m \u001b[39m0.999\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_PPO.ipynb#X52sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     optimizer_critic \u001b[39m=\u001b[39m optimizer_critic,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_PPO.ipynb#X52sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     summary_writer\u001b[39m=\u001b[39m summary_writer)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_PPO.ipynb#X52sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m agent\u001b[39m.\u001b[39;49mlearn(\u001b[39m400\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\61417\\Documents\\Units\\thesis_preparation\\right_left_brain_rl\\experiment\\working\\learn_tensorflow\\learning_tensorflow_RL_PPO.ipynb Cell 11\u001b[0m line \u001b[0;36m5\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_PPO.ipynb#X52sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m t_so_far \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_PPO.ipynb#X52sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m \u001b[39mwhile\u001b[39;00m t_so_far \u001b[39m<\u001b[39m total_timesteps:\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_PPO.ipynb#X52sZmlsZQ%3D%3D?line=52'>53</a>\u001b[0m     batch_states, batch_actions, batch_log_probs, batch_rewards, batch_lens, batch_dones, batch_values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrollout()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_PPO.ipynb#X52sZmlsZQ%3D%3D?line=54'>55</a>\u001b[0m     A_k \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_gae(batch_rewards, batch_values, batch_dones)\u001b[39m#batch_returns - V\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_PPO.ipynb#X52sZmlsZQ%3D%3D?line=55'>56</a>\u001b[0m     V, _, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluate(batch_states, batch_actions)\n",
      "\u001b[1;32mc:\\Users\\61417\\Documents\\Units\\thesis_preparation\\right_left_brain_rl\\experiment\\working\\learn_tensorflow\\learning_tensorflow_RL_PPO.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_PPO.ipynb#X52sZmlsZQ%3D%3D?line=131'>132</a>\u001b[0m batch_states\u001b[39m.\u001b[39mappend(state)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_PPO.ipynb#X52sZmlsZQ%3D%3D?line=133'>134</a>\u001b[0m \u001b[39m# pad states for use in lstm\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_PPO.ipynb#X52sZmlsZQ%3D%3D?line=134'>135</a>\u001b[0m padded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpad_input(batch_states, ep_t \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_PPO.ipynb#X52sZmlsZQ%3D%3D?line=135'>136</a>\u001b[0m action, log_prob \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_action(padded)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_PPO.ipynb#X52sZmlsZQ%3D%3D?line=136'>137</a>\u001b[0m value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcritic(tf\u001b[39m.\u001b[39mexpand_dims(padded, \u001b[39m0\u001b[39m)) \u001b[39m# may need to adjust dims?\u001b[39;00m\n",
      "\u001b[1;32mc:\\Users\\61417\\Documents\\Units\\thesis_preparation\\right_left_brain_rl\\experiment\\working\\learn_tensorflow\\learning_tensorflow_RL_PPO.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_PPO.ipynb#X52sZmlsZQ%3D%3D?line=176'>177</a>\u001b[0m pad_size \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmax([\u001b[39m0\u001b[39m, window_size\u001b[39m-\u001b[39mtf\u001b[39m.\u001b[39mshape(to_pad)[\u001b[39m0\u001b[39m]], axis \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m)\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_PPO.ipynb#X52sZmlsZQ%3D%3D?line=178'>179</a>\u001b[0m \u001b[39m# get the padded vals\u001b[39;00m\n\u001b[1;32m--> <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_PPO.ipynb#X52sZmlsZQ%3D%3D?line=179'>180</a>\u001b[0m padded \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mpad(to_pad, [[\u001b[39m0\u001b[39;49m,pad_size],[\u001b[39m0\u001b[39;49m,\u001b[39m0\u001b[39;49m]])\n\u001b[0;32m    <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_PPO.ipynb#X52sZmlsZQ%3D%3D?line=181'>182</a>\u001b[0m \u001b[39mreturn\u001b[39;00m padded\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\tensorflow\\python\\eager\\execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[0;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[0;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[0;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[0;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[0;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[0;32m     59\u001b[0m   ]\n\u001b[1;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__Pad_device_/job:localhost/replica:0/task:0/device:CPU:0}} The first dimension of paddings must be the rank of inputs[2,2] [0] [Op:Pad]"
     ]
    }
   ],
   "source": [
    "agent = LSTMPPO(        \n",
    "    env_name = ENV,\n",
    "    gamma = 0.999,\n",
    "    lam = 0.98,\n",
    "    ent_coef = 0.01,\n",
    "    vf_coef = 0.4,\n",
    "    clip = 0.2,\n",
    "    window_size = 4,\n",
    "    timesteps_per_batch = 40,\n",
    "    max_timesteps_per_episode = 20,\n",
    "    n_updates_per_iteration = 2,\n",
    "    actor = actor,\n",
    "    optimizer_actor = optimizer_actor,\n",
    "    critic = critic,\n",
    "    optimizer_critic = optimizer_critic,\n",
    "    summary_writer= summary_writer)\n",
    "    \n",
    "agent.learn(400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_states, batch_actions, batch_log_probs, batch_rewards, batch_lens, batch_values, batch_dones = agent.rollout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    def _prepare_batch_for_lstm(self, batch_states):\n",
    "        \"\"\"wraps states into lstm sequence format\"\"\"\n",
    "        ## need the initial k \n",
    "\n",
    "        initial_padded_states = tf.convert_to_tensor([tf.pad(states[:(i+1)][::-1], [[0,np.max([0, self.window_size-(i+1)], axis = 0)],[0,0]]) for i in tf.range(0, self.window_size)])\n",
    "        remaining_states = tf.convert_to_tensor([states[(i-self.window_size):i] for i in tf.range(self.window_size, tf.shape(states)[0])])\n",
    "        combined_states = tf.concat([initial_padded_states, remaining_states], axis = 0)\n",
    "\n",
    "        return combined_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(400, 4, 8), dtype=float32, numpy=\n",
       "array([[[-0.00742321,  1.4109877 , -0.75190264, ...,  0.17031702,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[-0.01479359,  1.4111564 , -0.7458402 , ...,  0.17382638,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.00742321,  1.4109877 , -0.75190264, ...,  0.17031702,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       [[-0.02225256,  1.4115062 , -0.75249255, ...,  0.13054022,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.01479359,  1.4111564 , -0.7458402 , ...,  0.17382638,\n",
       "          0.        ,  0.        ],\n",
       "        [-0.00742321,  1.4109877 , -0.75190264, ...,  0.17031702,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.03362102,  0.03272003,  0.10634845, ..., -0.7882775 ,\n",
       "          0.        ,  1.        ],\n",
       "        [-0.03352003,  0.02867847,  0.05531906, ..., -1.1004484 ,\n",
       "          0.        ,  1.        ],\n",
       "        [-0.0334713 ,  0.02452019,  0.06026066, ..., -1.2953523 ,\n",
       "          0.        ,  1.        ],\n",
       "        [-0.03404198,  0.02104083,  0.00201652, ..., -1.3302488 ,\n",
       "          0.        ,  1.        ]],\n",
       "\n",
       "       [[-0.03352003,  0.02867847,  0.05531906, ..., -1.1004484 ,\n",
       "          0.        ,  1.        ],\n",
       "        [-0.0334713 ,  0.02452019,  0.06026066, ..., -1.2953523 ,\n",
       "          0.        ,  1.        ],\n",
       "        [-0.03404198,  0.02104083,  0.00201652, ..., -1.3302488 ,\n",
       "          0.        ,  1.        ],\n",
       "        [-0.03459568,  0.01698419,  0.00414051, ..., -1.2946327 ,\n",
       "          0.        ,  1.        ]],\n",
       "\n",
       "       [[-0.0334713 ,  0.02452019,  0.06026066, ..., -1.2953523 ,\n",
       "          0.        ,  1.        ],\n",
       "        [-0.03404198,  0.02104083,  0.00201652, ..., -1.3302488 ,\n",
       "          0.        ,  1.        ],\n",
       "        [-0.03459568,  0.01698419,  0.00414051, ..., -1.2946327 ,\n",
       "          0.        ,  1.        ],\n",
       "        [-0.03539982,  0.01370131, -0.01763222, ..., -1.3287746 ,\n",
       "          0.        ,  0.        ]]], dtype=float32)>"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_padded_states = tf.convert_to_tensor([tf.pad(batch_states[:(i+1)][::-1], [[0,np.max([0, window_size-(i+1)], axis = 0)],[0,0]]) for i in tf.range(0, window_size)])\n",
    "remaining_states = tf.convert_to_tensor([batch_states[(i-window_size):i] for i in tf.range(window_size, tf.shape(batch_states)[0])])\n",
    "combined_states = tf.concat([initial_padded_states, remaining_states], axis = 0)\n",
    "\n",
    "combined_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_padded_states = tf.convert_to_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "4\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "window_size = 4\n",
    "for i in range(1, 10):\n",
    "    # print(i, batch_states[:i])\n",
    "    to_pad = batch_states[(i - window_size):i]\n",
    "\n",
    "    # get size of padding - 0 if we have enough\n",
    "    pad_size = np.max([0, window_size-tf.shape(to_pad)[0]], axis = 0)\n",
    "    print(pad_size)\n",
    "    \n",
    "    # get the padded vals\n",
    "    padded = tf.pad(to_pad, [[0,pad_size],[0,0]])\n",
    "    # padded = tf.expand_dims(padded, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 8), dtype=float32, numpy=\n",
       "array([[-0.04458275,  1.4089558 , -0.7465483 , -0.06464802,  0.04220025,\n",
       "         0.10646494,  0.        ,  0.        ],\n",
       "       [-0.05202141,  1.4081697 , -0.7492876 , -0.03510208,  0.04756383,\n",
       "         0.10728167,  0.        ,  0.        ],\n",
       "       [-0.05937738,  1.4068006 , -0.73888695, -0.06095807,  0.05082559,\n",
       "         0.06524126,  0.        ,  0.        ],\n",
       "       [-0.06678429,  1.4048368 , -0.7452685 , -0.08743688,  0.05536009,\n",
       "         0.09069827,  0.        ,  0.        ]], dtype=float32)>"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "V, _ = agent.evaluate(batch_states, batch_actions)\n",
    "\n",
    "A_k = agent.compute_gae(batch_rewards, batch_dones, batch_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1646, 1), dtype=float32, numpy=\n",
       "array([[-102.52281],\n",
       "       [-102.54475],\n",
       "       [-104.07944],\n",
       "       ...,\n",
       "       [-121.56047],\n",
       "       [-110.15443],\n",
       "       [ -99.06322]], dtype=float32)>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=30457.723>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(tf.pow(tf.squeeze(A_k) + V - V, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-1.1761721e+20>"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(tf.squeeze(A_k) + V - V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(187,), dtype=float32, numpy=\n",
       "array([ -35.858765,  -36.00548 ,  -36.13461 ,  -35.78525 ,  -35.179222,\n",
       "        -34.822395,  -34.400253,  -34.627316,  -36.89905 ,  -36.64887 ,\n",
       "        -35.568336,  -35.437412,  -35.054546,  -36.05531 ,  -37.551857,\n",
       "        -38.17431 ,  -38.348904,  -38.044655,  -37.409275,  -36.980873,\n",
       "        -36.51348 ,  -36.969887,  -36.618206,  -36.243736,  -35.851246,\n",
       "        -36.930576,  -36.50202 ,  -36.06474 ,  -36.534584,  -37.81839 ,\n",
       "        -37.37968 ,  -38.743984,  -40.301453,  -41.512123,  -41.2096  ,\n",
       "        -40.90464 ,  -40.600693,  -43.584766,  -45.699337,  -47.365635,\n",
       "        -47.571312,  -47.368546,  -47.170036,  -49.245472,  -50.742073,\n",
       "        -50.734814,  -52.331966,  -53.164597,  -53.96962 ,  -55.591103,\n",
       "        -55.516636,  -56.25157 ,  -58.49578 ,  -59.12402 ,  -59.894974,\n",
       "        -60.31041 ,  -63.66343 ,  -66.03956 ,  -67.37953 ,  -66.11544 ,\n",
       "        -65.71556 ,  -66.781815,  -65.89396 ,  -66.83498 ,  -66.22196 ,\n",
       "        -68.48559 ,  -67.97073 ,  -67.80147 ,  -67.63521 ,  -69.6291  ,\n",
       "        -69.44245 ,  -69.25106 ,  -71.69416 ,  -71.48259 ,  -71.25518 ,\n",
       "        -71.00665 ,  -70.730835,  -73.31058 ,  -74.09998 ,  -74.223564,\n",
       "        -75.30555 ,  -76.17385 ,  -75.33795 ,  -74.41805 ,  -74.71882 ,\n",
       "        -78.08437 ,  -80.848564,  -79.483574,  -81.758705,  -83.9969  ,\n",
       "        -82.53628 ,  -95.80769 , -100.      , -111.562935, -111.93571 ,\n",
       "       -112.27964 , -111.452034, -112.54805 , -112.84384 , -112.78916 ,\n",
       "       -113.81143 , -115.291534, -115.90666 , -116.96858 , -116.53733 ,\n",
       "       -116.90466 , -117.19567 , -117.568405, -116.798485, -116.99402 ,\n",
       "       -117.16815 , -116.43873 , -115.799286, -115.64611 , -115.47261 ,\n",
       "       -115.28014 , -115.187004, -113.83085 , -114.135956, -113.5689  ,\n",
       "       -113.00926 , -112.82377 , -112.62243 , -112.40657 , -112.10076 ,\n",
       "       -112.57909 , -113.35675 , -113.39822 , -113.43241 , -114.19871 ,\n",
       "       -114.36092 , -114.16507 , -114.35271 , -114.53908 , -114.725174,\n",
       "       -114.05531 , -114.08521 , -113.208664, -113.30276 , -114.50802 ,\n",
       "       -115.19201 , -114.883156, -114.76636 , -115.72358 , -117.23308 ,\n",
       "       -116.6491  , -117.82607 , -117.95957 , -118.34849 , -118.727776,\n",
       "       -117.70779 , -116.30205 , -115.6763  , -116.3317  , -116.620926,\n",
       "       -116.88761 , -117.20163 , -117.98565 , -117.410904, -118.34701 ,\n",
       "       -118.55635 , -118.729256, -117.752396, -117.88138 , -117.96356 ,\n",
       "       -117.99491 , -117.46392 , -117.28254 , -117.03548 , -116.71763 ,\n",
       "       -116.259964, -115.78657 , -113.85248 , -113.027336, -112.16679 ,\n",
       "       -111.204765, -110.135826, -108.77779 , -107.503075, -104.99027 ,\n",
       "       -103.24457 , -101.3665  ,  -99.35146 ,  -97.19513 ,  -93.84117 ,\n",
       "       -110.00367 , -100.      ], dtype=float32)>"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(ENV, render_mode='human')\n",
    "for i in range(30):\n",
    "    state, _ = env.reset()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "property 'render_mode' of 'TimeLimit' object has no setter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\61417\\Documents\\Units\\thesis_preparation\\right_left_brain_rl\\experiment\\working\\learn_tensorflow\\learning_tensorflow_RL_PPO.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_PPO.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m env\u001b[39m.\u001b[39;49mrender_mode \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhuman\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_PPO.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m env\u001b[39m.\u001b[39mrender()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/61417/Documents/Units/thesis_preparation/right_left_brain_rl/experiment/working/learn_tensorflow/learning_tensorflow_RL_PPO.ipynb#X22sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m state, _ \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mreset()\n",
      "\u001b[1;31mAttributeError\u001b[0m: property 'render_mode' of 'TimeLimit' object has no setter"
     ]
    }
   ],
   "source": [
    "env.render_mode = 'human'\n",
    "env.render()\n",
    "state, _ = env.reset()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_states, batch_actions, batch_log_probs, batch_returns, batch_lens = agent.rollout()\n",
    "\n",
    "### TODO: Where does the gradient tape start for tf? here?\n",
    "V, _ = agent.evaluate(batch_states, batch_actions)\n",
    "\n",
    "A_k = batch_returns - V\n",
    "\n",
    "# normalise advantages\n",
    "A_k = (A_k - tf.reduce_mean(A_k)) / (tf.math.reduce_std(A_k) + 1.0e-10)\n",
    "\n",
    "for _ in range(1):\n",
    "    _, curr_log_probs = agent.evaluate(batch_states, batch_actions)\n",
    "    # this is the start of our computation graph?\n",
    "    ratios = tf.exp(curr_log_probs - tf.squeeze(batch_log_probs))\n",
    "\n",
    "    # calc surrogate losses\n",
    "    surr1 = ratios * A_k\n",
    "    surr2 = tf.clip_by_value(ratios, 1 - agent.clip, 1 + agent.clip) * A_k\n",
    "\n",
    "    # actor_loss = tf.math.minimum(surr1, surr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=-8.606018e-08>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(-tf.math.minimum(surr1, surr2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
       "array([1.        , 1.0000002 , 0.99999976, 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.0000002 , 1.        , 1.        ,\n",
       "       1.        , 1.0000005 , 1.        , 1.        , 1.        ,\n",
       "       1.        , 1.        , 1.0000002 , 1.0000002 , 1.        ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratios"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
